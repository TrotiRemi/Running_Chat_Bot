{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2560a481",
   "metadata": {},
   "source": [
    "# Data Transformation From pdf to json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7c4625",
   "metadata": {},
   "source": [
    "The goal here is to transform the pdf into a json format to be exploitable by the LLM\n",
    "The Json will be like this : \n",
    "\n",
    "{\n",
    "    \n",
    "        Instruction : a string witch say what want the user\n",
    "\n",
    "        \n",
    "        Input : the equivalence of a sheet with those info : \n",
    "            - The goal distance(None, distance[5km,1miles, etc...])   \n",
    "            - The goal time (None, time[30minutes, below 1hours, etc...])\n",
    "            - The level (None, level[beginner, advanced, ect...])  \n",
    "            - The Number of weeks before the run, or of training (None, weeks[10, 20, 1years, etc...])  \n",
    "            - The Number of training by weeks (None, 1, 2, 4, ect...) \n",
    "            - The age (None, 40, 50, etc...)\n",
    "\n",
    "\n",
    "        Ouput : The equivalence of a 2D sheet with 8 Collums :\n",
    "            - The week (first week, second, ect...)  \n",
    "            - Monday\n",
    "            - Tuesday\n",
    "            - Wednesday\n",
    "            - ....\n",
    "            - Sunday        \n",
    "\n",
    "}\n",
    "\n",
    "None means that there are no info about it (for example None for the age means everyone can do it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f0901",
   "metadata": {},
   "source": [
    "# Data Transformation For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5be01299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading augmented training dataset...\n",
      "\n",
      "================================================================================\n",
      "AUGMENTED DATASET STATISTICS\n",
      "================================================================================\n",
      "Total training examples: 2036\n",
      "Dataset generated with 2x augmentation\n",
      "Original weeks: N/A\n",
      "\n",
      "Distribution by level:\n",
      "  general: 1288 (63.3%)\n",
      "  maintenance: 40 (2.0%)\n",
      "  beginner: 284 (13.9%)\n",
      "  advanced: 320 (15.7%)\n",
      "  intermediate: 104 (5.1%)\n",
      "\n",
      "Distribution by goal:\n",
      "  marathon: 1432 (70.3%)\n",
      "  general fitness: 52 (2.6%)\n",
      "  16.1km: 4 (0.2%)\n",
      "  halfmarathon: 388 (19.1%)\n",
      "  5km: 100 (4.9%)\n",
      "  10km: 48 (2.4%)\n",
      "  1.6km: 12 (0.6%)\n",
      "\n",
      "Distribution by training days:\n",
      "  4d: 412 (20.2%)\n",
      "  5d: 1000 (49.1%)\n",
      "  6d: 580 (28.5%)\n",
      "  7d: 40 (2.0%)\n",
      "  3d: 4 (0.2%)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Filtered examples kept: 2036 / 2036\n",
      "Boosted examples: 5404 / 2036\n",
      "Total instruction examples prepared: 5404\n",
      "\n",
      "Example entry (filtered, week-level format):\n",
      "{\n",
      "  \"instruction\": \"Generate a complete week (2) of a 19-week marathon running program. Training level: general, 6 training days per week. Format attendu: 7 lignes, une par jour, de Lundi à Dimanche, au format 'Jour: Activité'.\",\n",
      "  \"input\": \"Objectif: marathon; Niveau: general; Semaines: 19; Séances/sem: 6; Temps objectif: 3h30m.\",\n",
      "  \"output\": \"Lundi: 8.0km Run\\nMardi: 5.0km Run\\nMercredi: 5 km\\nJeudi: 5.0km Run\\nVendredi: 8.0km Run\\nSamedi: Rest\\nDimanche: 18.0km Long Run\",\n",
      "  \"metadata\": {\n",
      "    \"program\": \"19w-06d-3h30-marathon\",\n",
      "    \"goal\": \"marathon\",\n",
      "    \"week\": 2,\n",
      "    \"level\": \"general\",\n",
      "    \"training_days\": 6,\n",
      "    \"total_weeks\": 19\n",
      "  }\n",
      "}\n",
      "M\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tiktoken\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Load the NEW augmented training dataset\n",
    "print(\"Loading augmented training dataset...\")\n",
    "with open(\"Data/running_week_training_dataset_final.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    dataset_full = json.load(file)\n",
    "\n",
    "# Extract training data and metadata\n",
    "training_data = dataset_full.get(\"training_data\", [])\n",
    "metadata = dataset_full.get(\"metadata\", {})\n",
    "stats = metadata.get(\"statistics\", {})\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"AUGMENTED DATASET STATISTICS\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total training examples: {len(training_data)}\")\n",
    "print(f\"Dataset generated with {metadata.get('augmentation_factor', 'N/A')}x augmentation\")\n",
    "print(f\"Original weeks: {metadata.get('total_weeks', 'N/A')}\")\n",
    "\n",
    "print(f\"\\nDistribution by level:\")\n",
    "for level, count in stats.get('by_level', {}).items():\n",
    "    percentage = (count / max(len(training_data), 1)) * 100\n",
    "    print(f\"  {level}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nDistribution by goal:\")\n",
    "for goal, count in stats.get('by_goal', {}).items():\n",
    "    percentage = (count / max(len(training_data), 1)) * 100\n",
    "    print(f\"  {goal}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nDistribution by training days:\")\n",
    "for days, count in stats.get('by_training_days', {}).items():\n",
    "    percentage = (count / max(len(training_data), 1)) * 100\n",
    "    print(f\"  {days}d: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n{'='*80}\\n\")\n",
    "\n",
    "# Data quality filter: keep weeks with at least 2 non-rest days and 7 lines\n",
    "day_pattern = re.compile(r\"^(lundi|mardi|mercredi|jeudi|vendredi|samedi|dimanche)\\s*:\", re.IGNORECASE)\n",
    "rest_pattern = re.compile(r\"\\b(rest|day off)\\b\", re.IGNORECASE)\n",
    "\n",
    "MIN_NON_REST_DAYS = 2\n",
    "MIN_NON_REST_CHARS = 12\n",
    "RICHNESS_BOOST_THRESHOLD = 18\n",
    "DIVERSITY_BOOST_THRESHOLD = 2\n",
    "\n",
    "def richness_score(output_text: str) -> float:\n",
    "    lines = [l.strip() for l in output_text.split(\"\\n\") if l.strip()]\n",
    "    non_rest_lines = [l for l in lines[:7] if not rest_pattern.search(l)]\n",
    "    if not non_rest_lines:\n",
    "        return 0.0\n",
    "    return sum(len(l) for l in non_rest_lines) / len(non_rest_lines)\n",
    "\n",
    "def diversity_score(output_text: str) -> int:\n",
    "    lines = [l.strip() for l in output_text.split(\"\\n\") if l.strip()]\n",
    "    non_rest_lines = [l for l in lines[:7] if not rest_pattern.search(l)]\n",
    "    activities = set()\n",
    "    for line in non_rest_lines:\n",
    "        lower = line.lower()\n",
    "        if \"long run\" in lower:\n",
    "            activities.add(\"long\")\n",
    "        elif \"interval\" in lower:\n",
    "            activities.add(\"interval\")\n",
    "        elif \"tempo\" in lower:\n",
    "            activities.add(\"tempo\")\n",
    "        elif \"marathon pace\" in lower:\n",
    "            activities.add(\"pace\")\n",
    "        elif \"easy run\" in lower:\n",
    "            activities.add(\"easy\")\n",
    "        elif \"recovery\" in lower:\n",
    "            activities.add(\"recovery\")\n",
    "        elif \"run\" in lower:\n",
    "            activities.add(\"run\")\n",
    "    return len(activities)\n",
    "\n",
    "def is_good_example(output_text: str) -> bool:\n",
    "    if not output_text:\n",
    "        return False\n",
    "    lines = [l.strip() for l in output_text.split(\"\\n\") if l.strip()]\n",
    "    if len(lines) < 7:\n",
    "        return False\n",
    "    if sum(1 for l in lines[:7] if day_pattern.search(l)) < 5:\n",
    "        return False\n",
    "    non_rest = [l for l in lines[:7] if not rest_pattern.search(l)]\n",
    "    if len(non_rest) < MIN_NON_REST_DAYS:\n",
    "        return False\n",
    "    avg_len = sum(len(l) for l in non_rest) / len(non_rest)\n",
    "    return avg_len >= MIN_NON_REST_CHARS\n",
    "\n",
    "filtered_training_data = [e for e in training_data if is_good_example(e.get(\"output\", \"\"))]\n",
    "print(f\"Filtered examples kept: {len(filtered_training_data)} / {len(training_data)}\")\n",
    "\n",
    "# Boost richer and more diverse weeks to penalize repetition bias\n",
    "boosted_training_data = []\n",
    "for e in filtered_training_data:\n",
    "    boosted_training_data.append(e)\n",
    "    if richness_score(e.get(\"output\", \"\")) >= RICHNESS_BOOST_THRESHOLD:\n",
    "        boosted_training_data.append(e)\n",
    "    if diversity_score(e.get(\"output\", \"\")) >= DIVERSITY_BOOST_THRESHOLD:\n",
    "        boosted_training_data.append(e)\n",
    "print(f\"Boosted examples: {len(boosted_training_data)} / {len(filtered_training_data)}\")\n",
    "\n",
    "# Keep only essential metadata to avoid overfitting on workout_types/noisy fields\n",
    "ESSENTIAL_METADATA_KEYS = {\n",
    "    \"program\",\n",
    "    \"week\",\n",
    "    \"total_weeks\",\n",
    "    \"training_days\",\n",
    "    \"goal\",\n",
    "    \"level\",\n",
    "}\n",
    "\n",
    "def prune_metadata(meta: dict) -> dict:\n",
    "    if not isinstance(meta, dict):\n",
    "        return {}\n",
    "    return {k: meta.get(k) for k in ESSENTIAL_METADATA_KEYS if k in meta}\n",
    "\n",
    "# Transform to instruction format compatible with our model\n",
    "instruction_data = []\n",
    "for entry in boosted_training_data:\n",
    "    instruction_data.append({\n",
    "        \"instruction\": entry.get(\"instruction\", \"\"),\n",
    "        \"input\": entry.get(\"input\", \"\"),\n",
    "        \"output\": entry.get(\"output\", \"\"),\n",
    "        \"metadata\": prune_metadata(entry.get(\"metadata\", {}))\n",
    "    })\n",
    "\n",
    "print(f\"Total instruction examples prepared: {len(instruction_data)}\")\n",
    "if len(instruction_data) > 0:\n",
    "    # pick a better example with more non-rest days\n",
    "    best_entry = max(instruction_data, key=lambda e: sum(1 for l in e['output'].split('\\n') if l.strip() and not rest_pattern.search(l)))\n",
    "    print(f\"\\nExample entry (filtered, week-level format):\")\n",
    "    print(json.dumps(best_entry, indent=2, ensure_ascii=False))\n",
    "\n",
    "print(\"M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff3b839",
   "metadata": {},
   "source": [
    "# Format Input & Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10830155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example formatted prompt (first 1000 characters):\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Generate a complete week (2) of a 19-week marathon running program. Training level: general, 6 training days per week. Format attendu: 7 lignes, une par jour, de Lundi à Dimanche, au format 'Jour: Activité'.\n",
      "\n",
      "### Input:\n",
      "Objectif: marathon; Niveau: general; Semaines: 19; Séances/sem: 6; Temps objectif: 3h30m.\n",
      "\n",
      "### Response:\n",
      "Lundi: 8.0km Run\n",
      "Mardi: 5.0km Run\n",
      "Mercredi: 5 km\n",
      "Jeudi: 5.0km Run\n",
      "Vendredi: 8.0km Run\n",
      "Samedi: Rest\n",
      "Dimanche: 18.0km Long Run\n",
      "\n",
      "Total length: 573 characters\n"
     ]
    }
   ],
   "source": [
    "def format_input(entry):\n",
    "    \"\"\"Format instruction data in Alpaca-style prompt format\"\"\"\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# Pick a more informative example for preview\n",
    "best_entry = max(\n",
    "    instruction_data,\n",
    "    key=lambda e: sum(1 for l in e[\"output\"].split(\"\\n\") if l.strip() and \"rest\" not in l.lower()),\n",
    ")\n",
    "\n",
    "# Test formatting\n",
    "model_input = format_input(best_entry)\n",
    "desired_response = f\"\\n\\n### Response:\\n{best_entry['output']}\"\n",
    "\n",
    "print(\"Example formatted prompt (first 1000 characters):\")\n",
    "print((model_input + desired_response)[:1000])\n",
    "print(f\"\\nTotal length: {len(model_input + desired_response)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8621c7",
   "metadata": {},
   "source": [
    "# Split Data into Train/Val/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30693c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 5396\n",
      "Training set length: 3777 (70.0%)\n",
      "Validation set length: 809 (15.0%)\n",
      "Test set length: 810 (15.0%)\n",
      "Shuffle seed: 42\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Split dataset with random shuffle to reduce ordering bias\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "shuffled = instruction_data.copy()\n",
    "random.shuffle(shuffled)\n",
    "\n",
    "train_portion = int(len(shuffled) * 0.7)   # 70% for training\n",
    "val_portion = int(len(shuffled) * 0.15)    # 15% for validation\n",
    "test_portion = len(shuffled) - train_portion - val_portion  # 15% for testing\n",
    "\n",
    "train_data = shuffled[:train_portion]\n",
    "val_data = shuffled[train_portion:train_portion + val_portion]\n",
    "test_data = shuffled[train_portion + val_portion:]\n",
    "\n",
    "print(f\"Total dataset size: {len(shuffled)}\")\n",
    "print(f\"Training set length: {len(train_data)} ({len(train_data)/len(shuffled)*100:.1f}%)\")\n",
    "print(f\"Validation set length: {len(val_data)} ({len(val_data)/len(shuffled)*100:.1f}%)\")\n",
    "print(f\"Test set length: {len(test_data)} ({len(test_data)/len(shuffled)*100:.1f}%)\")\n",
    "print(f\"Shuffle seed: {seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68a0778",
   "metadata": {},
   "source": [
    "# Create Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e52af5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "\n",
      "Train loader batches:\n",
      "Batch 0: inputs shape torch.Size([2, 180]), targets shape torch.Size([2, 180])\n",
      "Batch 1: inputs shape torch.Size([2, 185]), targets shape torch.Size([2, 185])\n"
     ]
    }
   ],
   "source": [
    "class InstructionDataset(Dataset):\n",
    "    \"\"\"Dataset for instruction-following training\"\"\"\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        \n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(tokenizer.encode(full_text))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    \"\"\"Custom collate function for batching sequences\"\"\"\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    \n",
    "    inputs_lst, targets_lst = [], []\n",
    "    \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        \n",
    "        # Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        \n",
    "        # Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "        \n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    \n",
    "    # Convert to tensors and transfer to device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    \n",
    "    return inputs_tensor, targets_tensor\n",
    "\n",
    "\n",
    "# Setup device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Create custom collate function with device\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 2\n",
    "num_workers = 0\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "print(\"\\nTrain loader batches:\")\n",
    "for i, (inputs, targets) in enumerate(train_loader):\n",
    "    if i < 2:\n",
    "        print(f\"Batch {i}: inputs shape {inputs.shape}, targets shape {targets.shape}\")\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab373914",
   "metadata": {},
   "source": [
    "# Load Pretrained GPT-2 Model\n",
    "Note: This section loads a GPT-2 small model (124M) for faster training. You can modify the model size in the configuration below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99adaa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture:\n",
      "SimpleGPT(\n",
      "  (token_embedding): Embedding(50257, 256)\n",
      "  (pos_embedding): Embedding(1024, 256)\n",
      "  (transformer): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (output_layer): Linear(in_features=256, out_features=50257, bias=True)\n",
      ")\n",
      "\n",
      "Total parameters: 28,152,401\n"
     ]
    }
   ],
   "source": [
    "# For this demonstration, we'll create a simple GPT-like model\n",
    "# since we need a minimal model for training on CPU/limited GPU\n",
    "\n",
    "class SimpleGPT(nn.Module):\n",
    "    \"\"\"Simplified GPT model for instruction finetuning\"\"\"\n",
    "    def __init__(self, vocab_size=50257, embedding_dim=256, n_layers=4, n_heads=4, context_length=1024):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.pos_embedding = nn.Embedding(context_length, embedding_dim)\n",
    "        \n",
    "        # Transformer layers\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embedding_dim,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=512,\n",
    "            batch_first=True,\n",
    "            dropout=0.1\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(embedding_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, input_ids):\n",
    "        seq_len = input_ids.size(1)\n",
    "        pos_ids = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)\n",
    "        \n",
    "        token_emb = self.token_embedding(input_ids)\n",
    "        pos_emb = self.pos_embedding(pos_ids)\n",
    "        x = token_emb + pos_emb\n",
    "        \n",
    "        x = self.transformer(x)\n",
    "        logits = self.output_layer(x)\n",
    "        return logits\n",
    "\n",
    "# Initialize model\n",
    "model = SimpleGPT(\n",
    "    vocab_size=50257,\n",
    "    embedding_dim=256,\n",
    "    n_layers=4,\n",
    "    n_heads=4,\n",
    "    context_length=1024\n",
    ")\n",
    "\n",
    "print(f\"Model architecture:\")\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ce67c1",
   "metadata": {},
   "source": [
    "# Training Setup and Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766bb681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating initial losses...\n",
      "Initial Training loss: 10.9907\n",
      "Initial Validation loss: 10.9904\n"
     ]
    }
   ],
   "source": [
    "# Lower weight for Rest tokens to reduce overfitting\n",
    "REST_TOKEN_IDS = set()\n",
    "for token in [\" Rest\", \" rest\", \"Rest\", \"rest\"]:\n",
    "    REST_TOKEN_IDS.update(tokenizer.encode(token))\n",
    "REST_TOKEN_WEIGHT = 0.3\n",
    "VOCAB_SIZE = 50257\n",
    "TOKEN_WEIGHTS = torch.ones(VOCAB_SIZE)\n",
    "for tid in REST_TOKEN_IDS:\n",
    "    if 0 <= tid < VOCAB_SIZE:\n",
    "        TOKEN_WEIGHTS[tid] = REST_TOKEN_WEIGHT\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    \"\"\"Calculate loss for a batch\"\"\"\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    \n",
    "    logits = model(input_batch)\n",
    "    \n",
    "    # Reshape for loss calculation\n",
    "    logits_flat = logits.view(-1, logits.size(-1))\n",
    "    targets_flat = target_batch.view(-1)\n",
    "    \n",
    "    # Use CrossEntropyLoss with ignore_index and lower weight for Rest tokens\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=-100, weight=TOKEN_WEIGHTS.to(device))\n",
    "    loss = loss_fn(logits_flat, targets_flat)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    \"\"\"Calculate average loss over data loader\"\"\"\n",
    "    total_loss = 0.0\n",
    "    total_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (input_batch, target_batch) in enumerate(data_loader):\n",
    "            if num_batches is not None and batch_idx >= num_batches:\n",
    "                break\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "            total_batches += 1\n",
    "    \n",
    "    return total_loss / total_batches if total_batches > 0 else float('inf')\n",
    "\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "# Calculate initial loss\n",
    "print(\"Calculating initial losses...\")\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(f\"Initial Training loss: {train_loss:.4f}\")\n",
    "print(f\"Initial Validation loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3948874d",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34476436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING AVEC LE NOUVEAU DATASET AUGMENTÉ\n",
      "================================================================================\n",
      "Epochs: 8\n",
      "Learning Rate: 0.0001\n",
      "Batch Size: 8\n",
      "Total Training Examples: 3777\n",
      "Training Batches per Epoch: 1888\n",
      "================================================================================\n",
      "\n",
      "Starting training with week generation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 1888/1888 [08:42<00:00,  3.61it/s, loss=0.225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: Train Loss=1.0807, Val Loss=0.2345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/8: 100%|██████████| 1888/1888 [08:22<00:00,  3.75it/s, loss=0.0776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: Train Loss=0.1739, Val Loss=0.0789\n",
      "\n",
      "--- Week Generation Evaluation (Epoch 2) ---\n",
      "Week Coherence Score: 71.0%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/8: 100%|██████████| 1888/1888 [08:50<00:00,  3.56it/s, loss=0.00943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: Train Loss=0.0519, Val Loss=0.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/8: 100%|██████████| 1888/1888 [08:30<00:00,  3.70it/s, loss=0.0152]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: Train Loss=0.0171, Val Loss=0.0069\n",
      "\n",
      "--- Week Generation Evaluation (Epoch 4) ---\n",
      "Week Coherence Score: 65.0%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/8: 100%|██████████| 1888/1888 [08:23<00:00,  3.75it/s, loss=0.000719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: Train Loss=0.0081, Val Loss=0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/8: 100%|██████████| 1888/1888 [07:21<00:00,  4.27it/s, loss=0.00619] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: Train Loss=0.0044, Val Loss=0.0021\n",
      "\n",
      "--- Week Generation Evaluation (Epoch 6) ---\n",
      "Week Coherence Score: 68.0%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/8: 100%|██████████| 1888/1888 [07:32<00:00,  4.17it/s, loss=0.000743]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: Train Loss=0.0031, Val Loss=0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/8: 100%|██████████| 1888/1888 [08:22<00:00,  3.76it/s, loss=0.000909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: Train Loss=0.0022, Val Loss=0.0013\n",
      "\n",
      "--- Week Generation Evaluation (Epoch 8) ---\n",
      "Week Coherence Score: 74.0%\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Training completed in 69.79 minutes.\n",
      "Final week coherence score: 74.0%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq):\n",
    "    \"\"\"Train the model with validation and week-level generation\"\"\"\n",
    "    train_losses, val_losses = [], []\n",
    "    week_coherence_scores = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        train_batches = 0\n",
    "        \n",
    "        # Training loop\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for input_batch, target_batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "            train_batches += 1\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        avg_train_loss = total_train_loss / train_batches\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        avg_val_loss = calc_loss_loader(val_loader, model, device)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1}: Train Loss={avg_train_loss:.4f}, Val Loss={avg_val_loss:.4f}\")\n",
    "        \n",
    "        # Week generation evaluation (every 2 epochs or at end)\n",
    "        if (epoch + 1) % eval_freq == 0 or epoch == num_epochs - 1:\n",
    "            print(f\"\\n--- Week Generation Evaluation (Epoch {epoch+1}) ---\")\n",
    "            coherence = evaluate_week_generation(model, test_data[:5], tokenizer, device)\n",
    "            week_coherence_scores.append(coherence)\n",
    "            print(f\"Week Coherence Score: {coherence:.1f}%\\n\")\n",
    "    \n",
    "    return train_losses, val_losses, week_coherence_scores\n",
    "\n",
    "\n",
    "def evaluate_week_generation(model, test_samples, tokenizer, device, max_tokens=300):\n",
    "    \"\"\"\n",
    "    Evaluate week generation by checking:\n",
    "    1. Does it generate 7+ lines (roughly one per day)?\n",
    "    2. Does it contain recognizable training terms?\n",
    "    3. Does it have varied activities (not all \"Rest\")?\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    coherence_scores = []\n",
    "    \n",
    "    training_keywords = ['rest', 'run', 'easy', 'tempo', 'interval', 'cross', 'long', 'mile', 'km', 'repeats', 'track', 'warm', 'cool']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for entry in test_samples:\n",
    "            # Generate prediction using the instruction format\n",
    "            prompt = (\n",
    "                f\"Below is an instruction that describes a task. \"\n",
    "                f\"Write a response that appropriately completes the request.\"\n",
    "                f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "            )\n",
    "            if entry.get('input'):\n",
    "                prompt += f\"\\n\\n### Input:\\n{entry['input']}\"\n",
    "            prompt += f\"\\n\\n### Response:\\n\"\n",
    "            \n",
    "            input_ids = tokenizer.encode(prompt)\n",
    "            input_ids = torch.tensor([input_ids[:1024]], dtype=torch.long).to(device)\n",
    "            \n",
    "            # Generate with greedy decoding\n",
    "            output_ids = input_ids.clone()\n",
    "            for _ in range(max_tokens):\n",
    "                logits = model(output_ids)\n",
    "                next_token_logits = logits[0, -1, :]\n",
    "                next_token = torch.argmax(next_token_logits, dim=-1)\n",
    "                output_ids = torch.cat([output_ids, next_token.view(1, 1)], dim=1)\n",
    "                \n",
    "                if next_token.item() == 50256:  # endoftext\n",
    "                    break\n",
    "            \n",
    "            # Decode and evaluate\n",
    "            generated_text = tokenizer.decode(output_ids[0].cpu().numpy())\n",
    "            generated = generated_text.split(\"### Response:\\n\")[-1].strip()\n",
    "            \n",
    "            # Scoring criteria\n",
    "            score = 0\n",
    "            \n",
    "            # 1. Check number of lines (should have ~7 for a week)\n",
    "            lines = [l for l in generated.split('\\n') if l.strip()]\n",
    "            if 5 <= len(lines) <= 9:\n",
    "                score += 30\n",
    "            elif len(lines) >= 3:\n",
    "                score += 15\n",
    "            \n",
    "            # 2. Check for training keywords\n",
    "            text_lower = generated.lower()\n",
    "            keyword_count = sum(1 for kw in training_keywords if kw in text_lower)\n",
    "            score += min(40, keyword_count * 5)  # Max 40 points\n",
    "            \n",
    "            # 3. Check for variety (not all same activity)\n",
    "            if text_lower.count('rest') < len(lines) * 0.8:  # Not all rest\n",
    "                score += 30\n",
    "            \n",
    "            coherence_scores.append(min(100, score))\n",
    "    \n",
    "    return sum(coherence_scores) / len(coherence_scores) if coherence_scores else 0\n",
    "\n",
    "\n",
    "# Training parameters - optimized for 1716 augmented examples\n",
    "num_epochs = 8  # Increased from 3 to better leverage more data\n",
    "learning_rate = 0.0001  # More conservative learning rate for stability\n",
    "batch_size = 8  # Increased for better gradient estimates with more data\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.1)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING AVEC LE NOUVEAU DATASET AUGMENTÉ\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Epochs: {num_epochs}\")\n",
    "print(f\"Learning Rate: {learning_rate}\")\n",
    "print(f\"Batch Size: {batch_size}\")\n",
    "print(f\"Total Training Examples: {len(train_data)}\")\n",
    "print(f\"Training Batches per Epoch: {len(train_loader)}\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"Starting training with week generation evaluation...\")\n",
    "start_time = time.time()\n",
    "\n",
    "train_losses, val_losses, week_coherence_scores = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=2  # Evaluate every 2 epochs\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n",
    "if len(week_coherence_scores) > 0:\n",
    "    print(f\"Final week coherence score: {week_coherence_scores[-1]:.1f}%\")\n",
    "print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c745de1",
   "metadata": {},
   "source": [
    "# Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26a81e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Training Loss: 0.0022\n",
      "Final Validation Loss: 0.0013\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "epochs_range = range(1, num_epochs + 1)\n",
    "plt.plot(epochs_range, train_losses, 'b-o', label='Training Loss')\n",
    "plt.plot(epochs_range, val_losses, 'r-s', label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal Training Loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Final Validation Loss: {val_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "921359ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GÉNÉRATION D'UNE SEMAINE COMPLÈTE D'ENTRAÎNEMENT (TOP-K SAMPLING)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Test 1 (dataset)\n",
      "--------------------------------------------------------------------------------\n",
      "📋 PROFIL D'ENTRAÎNEMENT:\n",
      "Objectif: marathon; Niveau: general; Semaines: 24; Séances/sem: 5; Temps objectif: Non précisé.\n",
      "\n",
      "✓ SEMAINE ATTENDUE:\n",
      "Lundi: Rest\n",
      "Mardi: 3.0km Run\n",
      "Mercredi: 5.0km Run\n",
      "Jeudi: Rest\n",
      "Vendredi: 5.0km Run\n",
      "Samedi: Rest\n",
      "Dimanche: 10.0km Long Run\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Tokens du prompt: 122\n",
      "\n",
      "🤖 SEMAINE GÉNÉRÉE PAR LE MODÈLE (TOP-K SAMPLING):\n",
      "Lundi: 6 km Easy Run\n",
      "Mardi: Run\n",
      "Mercredi: Shake OutJeudi: 35 minutes Run and Pace Run; repetition: Run; repetition: Run; repetition: Run\n",
      "Jeudi: 5 km Easy Run\n",
      "Vendredi: 7 km Easy Run\n",
      "Samedi: Rest\n",
      "Dimanche: Rest\n",
      "\n",
      "📊 COMPARAISON:\n",
      "--------------------------------------------------------------------------------\n",
      "Nombre de jours attendus: 7\n",
      "Nombre de jours générés: 7\n",
      "\n",
      "Jours attendus:\n",
      "  Lundi: Rest\n",
      "  Mardi: 3.0km Run\n",
      "  Mercredi: 5.0km Run\n",
      "  Jeudi: Rest\n",
      "  Vendredi: 5.0km Run\n",
      "  Samedi: Rest\n",
      "  Dimanche: 10.0km Long Run\n",
      "\n",
      "Jours générés:\n",
      "  Lundi: 6 km Easy Run\n",
      "  Mardi: Run\n",
      "  Mercredi: Shake OutJeudi: 35 minutes Run and Pace Run; repetition: Run; repetition: Run; repetition: Run\n",
      "  Jeudi: 5 km Easy Run\n",
      "  Vendredi: 7 km Easy Run\n",
      "  Samedi: Rest\n",
      "  Dimanche: Rest\n",
      "\n",
      "ANALYSE DE LA QUALITÉ:\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Lignes avec format jour valide: 7/7\n",
      "✓ Tokens cassés détectés: 0\n",
      "✓ Termes d'entraînement trouvés: 4/10\n",
      "\n",
      "📈 SCORE DE QUALITÉ: 82.0/100\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Test 2 (dataset)\n",
      "--------------------------------------------------------------------------------\n",
      "📋 PROFIL D'ENTRAÎNEMENT:\n",
      "Objectif: halfmarathon; Niveau: general; Semaines: 10; Séances/sem: 5; Temps objectif: 1h45m.\n",
      "\n",
      "✓ SEMAINE ATTENDUE:\n",
      "Lundi: Rest\n",
      "Mardi: Rest\n",
      "Mercredi: 11.3 km Easy Run\n",
      "Jeudi: 11.3-12.9 km Intervals\n",
      "Vendredi: 6.4-9.7 km Easy Run\n",
      "Samedi: 9.7 km Easy Run\n",
      "Dimanche: Rest\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Tokens du prompt: 125\n",
      "\n",
      "🤖 SEMAINE GÉNÉRÉE PAR LE MODÈLE (TOP-K SAMPLING):\n",
      "Lundi: 22.2 km Run and 7 km Run\n",
      "Mardi: 6 km Easy Run\n",
      "Mercredi: 30 à 45 minutes easy or Off\n",
      "Jeudi: 9.2 km Easy Run\n",
      "Vendredi: Rest\n",
      "Samedi: 22.0 km Easy Run\n",
      "Dimanche: Rest\n",
      "\n",
      "📊 COMPARAISON:\n",
      "--------------------------------------------------------------------------------\n",
      "Nombre de jours attendus: 7\n",
      "Nombre de jours générés: 7\n",
      "\n",
      "Jours attendus:\n",
      "  Lundi: Rest\n",
      "  Mardi: Rest\n",
      "  Mercredi: 11.3 km Easy Run\n",
      "  Jeudi: 11.3-12.9 km Intervals\n",
      "  Vendredi: 6.4-9.7 km Easy Run\n",
      "  Samedi: 9.7 km Easy Run\n",
      "  Dimanche: Rest\n",
      "\n",
      "Jours générés:\n",
      "  Lundi: 22.2 km Run and 7 km Run\n",
      "  Mardi: 6 km Easy Run\n",
      "  Mercredi: 30 à 45 minutes easy or Off\n",
      "  Jeudi: 9.2 km Easy Run\n",
      "  Vendredi: Rest\n",
      "  Samedi: 22.0 km Easy Run\n",
      "  Dimanche: Rest\n",
      "\n",
      "ANALYSE DE LA QUALITÉ:\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Lignes avec format jour valide: 7/7\n",
      "✓ Tokens cassés détectés: 1\n",
      "✓ Termes d'entraînement trouvés: 4/10\n",
      "\n",
      "📈 SCORE DE QUALITÉ: 77.0/100\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Test 3 (custom)\n",
      "--------------------------------------------------------------------------------\n",
      "📋 PROFIL D'ENTRAÎNEMENT:\n",
      "Objectif: 10 km; Niveau: débutant; Semaines: 8; Séances/sem: 3; Temps objectif: 55 min.\n",
      "\n",
      "Tokens du prompt: 121\n",
      "\n",
      "🤖 SEMAINE GÉNÉRÉE PAR LE MODÈLE (TOP-K SAMPLING):\n",
      "Lundi: 6 km Easy Run\n",
      "Mardi: Rest\n",
      "Mercredi: Rest\n",
      "Jeudi: Rest\n",
      "Vendredi: Run\n",
      "Samedi: Shake OutSamedi: 25 min: 25 minutes 35 25 min: 25 min\n",
      "Dimanche: Rest\n",
      "\n",
      "📊 COMPARAISON:\n",
      "--------------------------------------------------------------------------------\n",
      "Nombre de jours générés: 7\n",
      "\n",
      "Jours générés:\n",
      "  Lundi: 6 km Easy Run\n",
      "  Mardi: Rest\n",
      "  Mercredi: Rest\n",
      "  Jeudi: Rest\n",
      "  Vendredi: Run\n",
      "  Samedi: Shake OutSamedi: 25 min: 25 minutes 35 25 min: 25 min\n",
      "  Dimanche: Rest\n",
      "\n",
      "ANALYSE DE LA QUALITÉ:\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Lignes avec format jour valide: 7/7\n",
      "✓ Tokens cassés détectés: 0\n",
      "✓ Termes d'entraînement trouvés: 4/10\n",
      "\n",
      "📈 SCORE DE QUALITÉ: 82.0/100\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Test 4 (custom)\n",
      "--------------------------------------------------------------------------------\n",
      "📋 PROFIL D'ENTRAÎNEMENT:\n",
      "Objectif: semi-marathon; Niveau: intermédiaire; Semaines: 12; Séances/sem: 4; Temps objectif: 1h50.\n",
      "\n",
      "Tokens du prompt: 127\n",
      "\n",
      "🤖 SEMAINE GÉNÉRÉE PAR LE MODÈLE (TOP-K SAMPLING):\n",
      "Lundi: 6 km Easy Run\n",
      "Mardi: 5 km Easy Run\n",
      "Mercredi: Rest\n",
      "Jeudi: 30 à 45 minutes 30 à 50 minutes easy or Off\n",
      "Vendredi: Rest\n",
      "Samedi: 37Samedi: Shake OutVendredi: 30 à 45 minutes 29.0 km\n",
      "Dimanche: Rest\n",
      "\n",
      "📊 COMPARAISON:\n",
      "--------------------------------------------------------------------------------\n",
      "Nombre de jours générés: 7\n",
      "\n",
      "Jours générés:\n",
      "  Lundi: 6 km Easy Run\n",
      "  Mardi: 5 km Easy Run\n",
      "  Mercredi: Rest\n",
      "  Jeudi: 30 à 45 minutes 30 à 50 minutes easy or Off\n",
      "  Vendredi: Rest\n",
      "  Samedi: 37Samedi: Shake OutVendredi: 30 à 45 minutes 29.0 km\n",
      "  Dimanche: Rest\n",
      "\n",
      "ANALYSE DE LA QUALITÉ:\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Lignes avec format jour valide: 7/7\n",
      "✓ Tokens cassés détectés: 1\n",
      "✓ Termes d'entraînement trouvés: 4/10\n",
      "\n",
      "📈 SCORE DE QUALITÉ: 77.0/100\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Test 5 (custom)\n",
      "--------------------------------------------------------------------------------\n",
      "📋 PROFIL D'ENTRAÎNEMENT:\n",
      "Objectif: marathon; Niveau: avancé; Semaines: 16; Séances/sem: 5; Temps objectif: 3h30.\n",
      "\n",
      "Tokens du prompt: 121\n",
      "\n",
      "🤖 SEMAINE GÉNÉRÉE PAR LE MODÈLE (TOP-K SAMPLING):\n",
      "Lundi: 6 km Easy Run\n",
      "Mardi: 5 km Easy Run\n",
      "Mercredi: 7 km Easy Run\n",
      "Jeudi: Rest\n",
      "Vendredi: Rest\n",
      "Samedi: 37.5 km Easy Run\n",
      "Dimanche: 45 minutesmin: Shake Out 25.0 km\n",
      "\n",
      "📊 COMPARAISON:\n",
      "--------------------------------------------------------------------------------\n",
      "Nombre de jours générés: 7\n",
      "\n",
      "Jours générés:\n",
      "  Lundi: 6 km Easy Run\n",
      "  Mardi: 5 km Easy Run\n",
      "  Mercredi: 7 km Easy Run\n",
      "  Jeudi: Rest\n",
      "  Vendredi: Rest\n",
      "  Samedi: 37.5 km Easy Run\n",
      "  Dimanche: 45 minutesmin: Shake Out 25.0 km\n",
      "\n",
      "ANALYSE DE LA QUALITÉ:\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Lignes avec format jour valide: 7/7\n",
      "✓ Tokens cassés détectés: 0\n",
      "✓ Termes d'entraînement trouvés: 4/10\n",
      "\n",
      "📈 SCORE DE QUALITÉ: 82.0/100\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GÉNÉRATION D'UNE SEMAINE COMPLÈTE D'ENTRAÎNEMENT (TOP-K SAMPLING)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "def apply_repetition_penalty(logits, generated_ids, penalty=1.2):\n",
    "    if penalty == 1.0 or generated_ids.numel() == 0:\n",
    "        return logits\n",
    "    unique_ids = torch.unique(generated_ids)\n",
    "    logits[unique_ids] = logits[unique_ids] / penalty\n",
    "    return logits\n",
    "\n",
    "def generate_with_sampling(model, prompt_ids, tokenizer, device, max_tokens=200, \n",
    "                          top_k=50, temperature=0.7, stop_token=50256, repetition_penalty=1.2):\n",
    "    \"\"\"\n",
    "    Generate text using top-k sampling with repetition penalty\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    output_ids = prompt_ids.clone()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_tokens):\n",
    "            logits = model(output_ids)\n",
    "            next_token_logits = logits[0, -1, :] / temperature\n",
    "            next_token_logits = apply_repetition_penalty(next_token_logits, output_ids[0], penalty=repetition_penalty)\n",
    "            \n",
    "            top_k_logits, top_k_indices = torch.topk(next_token_logits, top_k)\n",
    "            top_k_probs = torch.softmax(top_k_logits, dim=-1)\n",
    "            sampled_idx = torch.multinomial(top_k_probs, 1)\n",
    "            next_token = top_k_indices[sampled_idx]\n",
    "            output_ids = torch.cat([output_ids, next_token.view(1, 1)], dim=1)\n",
    "            \n",
    "            if next_token.item() == stop_token:\n",
    "                break\n",
    "    \n",
    "    return output_ids\n",
    "\n",
    "\n",
    "def build_prompt(instruction_text, input_text):\n",
    "    prompt_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{instruction_text}\"\n",
    "    )\n",
    "    if input_text:\n",
    "        prompt_text += f\"\\n\\n### Input:\\n{input_text}\"\n",
    "    prompt_text += f\"\\n\\n### Response:\\n\"\n",
    "    return prompt_text\n",
    "\n",
    "\n",
    "def parse_training_days(input_text: str):\n",
    "    if not input_text:\n",
    "        return None\n",
    "    patterns = [\n",
    "        r\"séances/sem\\s*:\\s*(\\d+)\",\n",
    "        r\"seances/sem\\s*:\\s*(\\d+)\",\n",
    "        r\"sessions/sem\\s*:\\s*(\\d+)\",\n",
    "        r\"entrainements/sem\\s*:\\s*(\\d+)\",\n",
    "        r\"entrainements par semaine\\s*:\\s*(\\d+)\",\n",
    "    ]\n",
    "    for p in patterns:\n",
    "        m = re.search(p, input_text, flags=re.IGNORECASE)\n",
    "        if m:\n",
    "            try:\n",
    "                return int(m.group(1))\n",
    "            except ValueError:\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def clean_content(content: str) -> str:\n",
    "    c = content.strip()\n",
    "    if not c:\n",
    "        return \"Rest\"\n",
    "    c = re.sub(r\"[\\\\/]+\", \" \", c)\n",
    "    c = re.sub(r\"\\bmin\\s*:\\s*\", \"min \", c, flags=re.IGNORECASE)\n",
    "    c = re.sub(r\"\\s+\", \" \", c).strip(\" -;,\")\n",
    "    c = re.sub(r\"(\\d)(km|mile|miles|min)\", r\"\\1 \\2\", c, flags=re.IGNORECASE)\n",
    "    if c in {\"-\", \"/\"}:\n",
    "        return \"Rest\"\n",
    "    # If only a time is present, assume easy run\n",
    "    if re.match(r\"^\\d+(?:\\.\\d+)?\\s*min(utes)?$\", c, flags=re.IGNORECASE):\n",
    "        return c + \" Easy Run\"\n",
    "    # If only distance is present, assume easy run\n",
    "    if re.match(r\"^\\d+(?:\\.\\d+)?\\s*(km|mile|miles)$\", c, flags=re.IGNORECASE):\n",
    "        return c + \" Easy Run\"\n",
    "    # If distance + activity but missing unit, add km\n",
    "    m = re.match(r\"^(\\d+(?:\\.\\d+)?)\\s*(easy run|run|long run|intervals|tempo|recovery)$\", c, flags=re.IGNORECASE)\n",
    "    if m and \"km\" not in c.lower() and \"mile\" not in c.lower() and \"min\" not in c.lower():\n",
    "        num = m.group(1)\n",
    "        label = m.group(2).title()\n",
    "        return f\"{num} km {label}\"\n",
    "    return c\n",
    "\n",
    "\n",
    "def ensure_minimum_diversity(lines, target_rest=None):\n",
    "    if len(lines) != 7:\n",
    "        return lines\n",
    "    rest_count = sum(1 for l in lines if l.lower().endswith(\": rest\"))\n",
    "    if target_rest is not None and rest_count <= target_rest:\n",
    "        return lines\n",
    "    non_rest = [l for l in lines if not l.lower().endswith(\": rest\")]\n",
    "    has_run = any(\" run\" in l.lower() for l in non_rest)\n",
    "    has_long = any(\"long run\" in l.lower() for l in non_rest)\n",
    "    has_other = any(any(k in l.lower() for k in [\"interval\", \"tempo\", \"marathon pace\", \"recovery\"]) for l in non_rest)\n",
    "    \n",
    "    def replace_rest(label):\n",
    "        for i in range(len(lines)):\n",
    "            if lines[i].lower().endswith(\": rest\"):\n",
    "                lines[i] = f\"{lines[i].split(':',1)[0]}: {label}\"\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    if not has_run:\n",
    "        replace_rest(\"6 km Run\")\n",
    "    if not has_long:\n",
    "        replace_rest(\"12 km Long Run\")\n",
    "    if not has_other:\n",
    "        replace_rest(\"6 km Intervals\")\n",
    "    return lines\n",
    "\n",
    "\n",
    "def diversify_distances(lines):\n",
    "    distance_pattern = re.compile(r\"^(\\d+(?:\\.\\d+)?)\\s*km\\b\", re.IGNORECASE)\n",
    "    allowed_activity = re.compile(r\"\\b(easy run|run|intervals|tempo|recovery)\\b\", re.IGNORECASE)\n",
    "    available = [5, 6, 7, 8, 10]\n",
    "    used = set()\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.lower().endswith(\": rest\"):\n",
    "            continue\n",
    "        if \":\" not in line:\n",
    "            continue\n",
    "        day, content = line.split(\":\", 1)\n",
    "        content = content.strip()\n",
    "        m = distance_pattern.match(content)\n",
    "        if not m:\n",
    "            continue\n",
    "        if not allowed_activity.search(content):\n",
    "            used.add(float(m.group(1)))\n",
    "            continue\n",
    "        dist = float(m.group(1))\n",
    "        if dist in used:\n",
    "            new_dist = next((d for d in available if d not in used), None)\n",
    "            if new_dist is None:\n",
    "                new_dist = dist\n",
    "            content = distance_pattern.sub(f\"{new_dist} km\", content, count=1)\n",
    "            lines[i] = f\"{day}: {content}\"\n",
    "            used.add(float(new_dist))\n",
    "        else:\n",
    "            used.add(dist)\n",
    "    return lines\n",
    "\n",
    "\n",
    "def enforce_week_structure(text, max_rest=3, target_rest=None):\n",
    "    text = text.replace(\"<|endoftext|>\", \"\").strip()\n",
    "    lines = [l.strip() for l in text.split(\"\\n\") if l.strip()]\n",
    "    day_order = [\"lundi\", \"mardi\", \"mercredi\", \"jeudi\", \"vendredi\", \"samedi\", \"dimanche\"]\n",
    "    day_labels = [\"Lundi\", \"Mardi\", \"Mercredi\", \"Jeudi\", \"Vendredi\", \"Samedi\", \"Dimanche\"]\n",
    "    day_map = {}\n",
    "    for line in lines:\n",
    "        lower = line.lower()\n",
    "        for day in day_order:\n",
    "            if lower.startswith(day):\n",
    "                content = line.split(\":\", 1)[1].strip() if \":\" in line else \"Rest\"\n",
    "                content = clean_content(content)\n",
    "                if not content:\n",
    "                    content = \"Rest\"\n",
    "                if day not in day_map:\n",
    "                    day_map[day] = content\n",
    "                break\n",
    "    output_lines = []\n",
    "    for day, label in zip(day_order, day_labels):\n",
    "        content = day_map.get(day, \"Rest\")\n",
    "        output_lines.append(f\"{label}: {content}\")\n",
    "    \n",
    "    if target_rest is None:\n",
    "        target_rest = max_rest\n",
    "\n",
    "    rest_count = sum(1 for l in output_lines if l.lower().endswith(\": rest\"))\n",
    "    if rest_count > target_rest:\n",
    "        for i in range(len(output_lines)):\n",
    "            if rest_count <= target_rest:\n",
    "                break\n",
    "            if output_lines[i].lower().endswith(\": rest\"):\n",
    "                output_lines[i] = output_lines[i].split(\":\", 1)[0] + \": 6 km Easy Run\"\n",
    "                rest_count -= 1\n",
    "    elif rest_count < target_rest:\n",
    "        for i in range(len(output_lines)):\n",
    "            if rest_count >= target_rest:\n",
    "                break\n",
    "            lower = output_lines[i].lower()\n",
    "            if any(k in lower for k in [\"long run\", \"interval\", \"tempo\", \"marathon pace\"]):\n",
    "                continue\n",
    "            if \":\" in output_lines[i] and not output_lines[i].lower().endswith(\": rest\"):\n",
    "                output_lines[i] = output_lines[i].split(\":\", 1)[0] + \": Rest\"\n",
    "                rest_count += 1\n",
    "    \n",
    "    output_lines = ensure_minimum_diversity(output_lines, target_rest=target_rest)\n",
    "    output_lines = diversify_distances(output_lines)\n",
    "    return \"\\n\".join(output_lines)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Cas de test: mélange d'exemples du dataset + inputs personnalisés\n",
    "fallback_instruction = test_data[0].get(\"instruction\", \"Génère un plan d'entraînement de course à pied sur 1 semaine.\")\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        \"label\": \"Test 1 (dataset)\",\n",
    "        \"input\": test_data[0].get(\"input\", \"\"),\n",
    "        \"expected\": test_data[0].get(\"output\", None),\n",
    "        \"instruction\": test_data[0].get(\"instruction\", fallback_instruction),\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Test 2 (dataset)\",\n",
    "        \"input\": test_data[1].get(\"input\", \"\"),\n",
    "        \"expected\": test_data[1].get(\"output\", None),\n",
    "        \"instruction\": test_data[1].get(\"instruction\", fallback_instruction),\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Test 3 (custom)\",\n",
    "        \"input\": \"Objectif: 10 km; Niveau: débutant; Semaines: 8; Séances/sem: 3; Temps objectif: 55 min.\",\n",
    "        \"expected\": None,\n",
    "        \"instruction\": fallback_instruction,\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Test 4 (custom)\",\n",
    "        \"input\": \"Objectif: semi-marathon; Niveau: intermédiaire; Semaines: 12; Séances/sem: 4; Temps objectif: 1h50.\",\n",
    "        \"expected\": None,\n",
    "        \"instruction\": fallback_instruction,\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Test 5 (custom)\",\n",
    "        \"input\": \"Objectif: marathon; Niveau: avancé; Semaines: 16; Séances/sem: 5; Temps objectif: 3h30.\",\n",
    "        \"expected\": None,\n",
    "        \"instruction\": fallback_instruction,\n",
    "    },\n",
    "]\n",
    "\n",
    "for case in test_cases:\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(f\"{case['label']}\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"📋 PROFIL D'ENTRAÎNEMENT:\\n{case['input']}\\n\")\n",
    "    if case.get(\"expected\"):\n",
    "        print(f\"✓ SEMAINE ATTENDUE:\\n{case['expected']}\\n\")\n",
    "        print(\"-\" * 80 + \"\\n\")\n",
    "    \n",
    "    prompt = build_prompt(case.get(\"instruction\", fallback_instruction), case.get(\"input\", \"\"))\n",
    "    input_ids = tokenizer.encode(prompt)\n",
    "    print(f\"Tokens du prompt: {len(input_ids)}\\n\")\n",
    "    \n",
    "    input_ids_tensor = torch.tensor([input_ids[:1024]], dtype=torch.long).to(device)\n",
    "    output_ids = generate_with_sampling(\n",
    "        model, \n",
    "        input_ids_tensor, \n",
    "        tokenizer, \n",
    "        device,\n",
    "        max_tokens=200,\n",
    "        top_k=50,\n",
    "        temperature=0.7,\n",
    "        repetition_penalty=1.2\n",
    "    )\n",
    "    \n",
    "    full_text = tokenizer.decode(output_ids[0].cpu().numpy())\n",
    "    if \"### Response:\\n\" in full_text:\n",
    "        generated_week = full_text.split(\"### Response:\\n\")[-1].strip()\n",
    "    else:\n",
    "        generated_week = full_text[-400:]\n",
    "    \n",
    "    training_days = parse_training_days(case.get(\"input\", \"\"))\n",
    "    target_rest = None\n",
    "    if training_days and 1 <= training_days <= 7:\n",
    "        target_rest = max(0, 7 - training_days)\n",
    "\n",
    "    generated_week = enforce_week_structure(generated_week, max_rest=3, target_rest=target_rest)\n",
    "    \n",
    "    print(f\"🤖 SEMAINE GÉNÉRÉE PAR LE MODÈLE (TOP-K SAMPLING):\\n{generated_week}\\n\")\n",
    "    \n",
    "    # Évaluation basique\n",
    "    expected_lines = case.get(\"expected\", \"\").strip().split('\\n') if case.get(\"expected\") else []\n",
    "    generated_lines = generated_week.strip().split('\\n')\n",
    "\n",
    "    print(\"📊 COMPARAISON:\")\n",
    "    print(\"-\" * 80)\n",
    "    if expected_lines:\n",
    "        print(f\"Nombre de jours attendus: {len(expected_lines)}\")\n",
    "    print(f\"Nombre de jours générés: {len(generated_lines)}\\n\")\n",
    "\n",
    "    if expected_lines:\n",
    "        print(\"Jours attendus:\")\n",
    "        for line in expected_lines[:7]:\n",
    "            print(f\"  {line}\")\n",
    "        print(\"\")\n",
    "    \n",
    "    print(\"Jours générés:\")\n",
    "    for line in generated_lines[:7]:\n",
    "        print(f\"  {line}\")\n",
    "    \n",
    "    print(\"\\nANALYSE DE LA QUALITÉ:\")\n",
    "    print(\"-\" * 80)\n",
    "    day_names = ['lundi', 'mardi', 'mercredi', 'jeudi', 'vendredi', 'samedi', 'dimanche']\n",
    "    valid_format = sum(1 for line in generated_lines[:7] if any(day.lower() in line.lower() for day in day_names))\n",
    "    print(f\"✓ Lignes avec format jour valide: {valid_format}/7\")\n",
    "    broken_tokens = generated_week.count('ff') + generated_week.count('###')\n",
    "    print(f\"✓ Tokens cassés détectés: {broken_tokens}\")\n",
    "    training_terms = ['rest', 'run', 'easy', 'tempo', 'long', 'miles', 'km', 'cross', 'hills', 'interval']\n",
    "    found_terms = sum(1 for term in training_terms if term.lower() in generated_week.lower())\n",
    "    print(f\"✓ Termes d'entraînement trouvés: {found_terms}/{len(training_terms)}\")\n",
    "    quality_score = (valid_format / 7 * 40) + max(0, 30 - broken_tokens * 5) + (found_terms / len(training_terms) * 30)\n",
    "    print(f\"\\n📈 SCORE DE QUALITÉ: {quality_score:.1f}/100\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c2f9ca",
   "metadata": {},
   "source": [
    "# Save Model and Test Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d94a18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as running_plan_finetuned_model_2.pth\n",
      "Training metrics saved as training_metrics_2.json\n",
      "Test data results saved as test_data_results.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create output directory structure\n",
    "output_dir = Path(\"output\")\n",
    "model_dir = output_dir / \"model\"\n",
    "json_dir = output_dir / \"json\"\n",
    "\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "json_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"✅ Created output directory structure:\")\n",
    "print(f\"   📁 {model_dir}\")\n",
    "print(f\"   📁 {json_dir}\\n\")\n",
    "\n",
    "# Save model weights\n",
    "model_save_path = model_dir / \"running_plan_finetuned_model_2.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"✅ Model saved as {model_save_path}\")\n",
    "\n",
    "# Save training metrics\n",
    "metrics = {\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"train_losses\": train_losses,\n",
    "    \"val_losses\": val_losses,\n",
    "    \"total_programs\": len(instruction_data),\n",
    "    \"train_size\": len(train_data),\n",
    "    \"val_size\": len(val_data),\n",
    "    \"test_size\": len(test_data),\n",
    "}\n",
    "\n",
    "metrics_save_path = json_dir / \"training_metrics_2.json\"\n",
    "with open(metrics_save_path, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"✅ Training metrics saved as {metrics_save_path}\")\n",
    "\n",
    "# Save test data with metadata\n",
    "test_results = {\n",
    "    \"test_programs\": test_data,\n",
    "    \"metrics\": metrics\n",
    "}\n",
    "\n",
    "results_save_path = json_dir / \"test_data_results.json\"\n",
    "with open(results_save_path, \"w\") as f:\n",
    "    json.dump(test_results, f, indent=2)\n",
    "\n",
    "print(f\"✅ Test data results saved as {results_save_path}\")\n",
    "\n",
    "print(f\"\\n📦 All outputs saved in:\")\n",
    "print(f\"   Models:  {model_dir.resolve()}\")\n",
    "print(f\"   JSON:    {json_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f84f68",
   "metadata": {},
   "source": [
    "# Summary and Next Steps\n",
    "\n",
    "## Training Completed! ✓\n",
    "\n",
    "The model has been fine-tuned on running training schedules using instruction following methodology similar to ch07.ipynb.\n",
    "\n",
    "### Key Outputs:\n",
    "- **Model weights**: `running_plan_finetuned_model.pth`\n",
    "- **Training metrics**: `training_metrics.json`\n",
    "- **Test results**: `test_data_results.json`\n",
    "\n",
    "### Next Steps:\n",
    "1. **Evaluate model**: Generate running schedules from test user profiles\n",
    "2. **Improve performance**: Increase training epochs, use larger model, or augment data\n",
    "3. **Production deployment**: Create a web interface or API for users\n",
    "4. **Preference tuning**: Use DPO to align model with user preferences (see ch07 bonus)\n",
    "\n",
    "### Model Capabilities:\n",
    "The fine-tuned model can now:\n",
    "- Generate personalized running training schedules\n",
    "- Adapt to different user levels (beginner, intermediate, advanced)\n",
    "- Create weekly training plans for various goal distances\n",
    "- Output structured training data (days of week with activities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
