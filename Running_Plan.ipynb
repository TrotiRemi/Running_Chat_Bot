{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2560a481",
   "metadata": {},
   "source": [
    "# Data Transformation From pdf to json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7c4625",
   "metadata": {},
   "source": [
    "The goal here is to transform the pdf into a json format to be exploitable by the LLM\n",
    "The Json will be like this : \n",
    "\n",
    "{\n",
    "    \n",
    "        Instruction : a string witch say what want the user\n",
    "\n",
    "        \n",
    "        Input : the equivalence of a sheet with those info : \n",
    "            - The goal distance(None, distance[5km,1miles, etc...])   \n",
    "            - The goal time (None, time[30minutes, below 1hours, etc...])\n",
    "            - The level (None, level[beginner, advanced, ect...])  \n",
    "            - The Number of weeks before the run, or of training (None, weeks[10, 20, 1years, etc...])  \n",
    "            - The Number of training by weeks (None, 1, 2, 4, ect...) \n",
    "            - The age (None, 40, 50, etc...)\n",
    "\n",
    "\n",
    "        Ouput : The equivalence of a 2D sheet with 8 Collums :\n",
    "            - The week (first week, second, ect...)  \n",
    "            - Monday\n",
    "            - Tuesday\n",
    "            - Wednesday\n",
    "            - ....\n",
    "            - Sunday        \n",
    "\n",
    "}\n",
    "\n",
    "None means that there are no info about it (for example None for the age means everyone can do it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06cb75ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement: 03d-5k-12w.pdf\n",
      "  ✓ Sauvegardé: Data\\json\\03d-5k-12w.json\n",
      "Traitement: 03d-halfmarathon-16w.pdf\n",
      "  ✓ Sauvegardé: Data\\json\\03d-halfmarathon-16w.json\n",
      "Traitement: 03d-marathon-16w.pdf\n",
      "  ✓ Sauvegardé: Data\\json\\03d-marathon-16w.json\n",
      "Traitement: 04d-20w-marathon.pdf\n",
      "  ✓ Sauvegardé: Data\\json\\04d-20w-marathon.json\n",
      "Traitement: 04d-50-maintenance-4w.pdf\n",
      "  ✓ Sauvegardé: Data\\json\\04d-50-maintenance-4w.json\n",
      "\n",
      "✓ 5 fichiers traités\n",
      "✓ JSON sauvegardés dans: Data\\json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import PyPDF2\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "def extract_features_from_filename(filename):\n",
    "    \"\"\"Extrait les caractéristiques du nom de fichier\"\"\"\n",
    "    \n",
    "    features = {\n",
    "        'goal_distance': None,\n",
    "        'goal_time': None,\n",
    "        'level': None,\n",
    "        'weeks_training': None,\n",
    "        'training_per_week': None,\n",
    "        'age': None\n",
    "    }\n",
    "    \n",
    "    name = filename.lower()\n",
    "    name_clean = re.sub(r'\\.(pdf|xlsx)$', '', name)\n",
    "    name_clean = re.sub(r'run\\s*walk\\s*', '', name_clean)\n",
    "    \n",
    "    # Distance\n",
    "    distance_match = re.search(r'(\\d+)\\s*(k|mile|miles)(?![a-z])', name_clean)\n",
    "    if distance_match:\n",
    "        value = int(distance_match.group(1))\n",
    "        unit = distance_match.group(2)\n",
    "        if unit in ['mile', 'miles']:\n",
    "            km = round(value * 1.609, 1)\n",
    "            features['goal_distance'] = f\"{km}km\"\n",
    "        else:\n",
    "            features['goal_distance'] = f\"{value}{unit}\"\n",
    "    elif 'halfmarathon' in name_clean or 'half-marathon' in name_clean:\n",
    "        features['goal_distance'] = 'halfmarathon'\n",
    "    elif 'marathon' in name_clean:\n",
    "        features['goal_distance'] = 'marathon'\n",
    "    \n",
    "    # Niveau\n",
    "    if 'beginner' in name_clean:\n",
    "        features['level'] = 'beginner'\n",
    "    elif 'intermediate' in name_clean:\n",
    "        features['level'] = 'intermediate'\n",
    "    elif 'advanced' in name_clean:\n",
    "        features['level'] = 'advanced'\n",
    "    elif 'maintenance' in name_clean:\n",
    "        features['level'] = 'maintenance'\n",
    "    \n",
    "    # Semaines\n",
    "    weeks_match = re.search(r'(\\d+)w', name_clean)\n",
    "    if weeks_match:\n",
    "        weeks = int(weeks_match.group(1))\n",
    "        if 1 <= weeks <= 100:\n",
    "            features['weeks_training'] = weeks\n",
    "    \n",
    "    # Jours par semaine\n",
    "    training_match = re.search(r'(\\d{1,2})d', name_clean)\n",
    "    if training_match:\n",
    "        training = int(training_match.group(1))\n",
    "        if 1 <= training <= 7:\n",
    "            features['training_per_week'] = training\n",
    "    \n",
    "    # Temps\n",
    "    time_match = re.search(r'(\\d+)h(\\d{1,2})', name_clean)\n",
    "    if time_match:\n",
    "        hours = time_match.group(1)\n",
    "        minutes = time_match.group(2)\n",
    "        features['goal_time'] = f\"{hours}h{minutes}m\"\n",
    "    else:\n",
    "        time_match = re.search(r'(\\d+)h(?![\\d])', name_clean)\n",
    "        if time_match:\n",
    "            features['goal_time'] = f\"{time_match.group(1)}h\"\n",
    "    \n",
    "    # Age\n",
    "    age_match = re.search(r'(?:^|[-_])(\\d{2})(?:[-_]|$)', name_clean)\n",
    "    if age_match:\n",
    "        age = int(age_match.group(1))\n",
    "        if 20 <= age <= 80:\n",
    "            features['age'] = age\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_training_schedule(pdf_path):\n",
    "    \"\"\"Extrait le planning d'entraînement d'un PDF avec détection de tableaux\"\"\"\n",
    "    \n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text()\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lecture {pdf_path}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    training_weeks = defaultdict(lambda: {\n",
    "        'monday': None,\n",
    "        'tuesday': None,\n",
    "        'wednesday': None,\n",
    "        'thursday': None,\n",
    "        'friday': None,\n",
    "        'saturday': None,\n",
    "        'sunday': None\n",
    "    })\n",
    "    \n",
    "    lines = text.split('\\n')\n",
    "    days = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "    \n",
    "    # Chercher les patterns \"WEEK X\" suivi d'un tableau\n",
    "    week_pattern = re.compile(r'WEEK\\s+(\\d+)', re.IGNORECASE)\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        week_match = week_pattern.search(line)\n",
    "        if week_match:\n",
    "            week_num = int(week_match.group(1))\n",
    "            \n",
    "            # Chercher la structure du tableau après \"WEEK X\"\n",
    "            # Parcourir les lignes suivantes pour trouver les en-têtes de jours\n",
    "            for j in range(i+1, min(i+50, len(lines))):\n",
    "                current_line = lines[j].strip()\n",
    "                \n",
    "                # Chercher les jours comme en-têtes\n",
    "                day_found = False\n",
    "                for day in days:\n",
    "                    if day.upper() in current_line.upper():\n",
    "                        day_found = True\n",
    "                        # Extraire le contenu du jour\n",
    "                        content = re.sub(day, '', current_line, flags=re.IGNORECASE).strip()\n",
    "                        if content and len(content) > 3:\n",
    "                            training_weeks[week_num][day] = content\n",
    "                        break\n",
    "                \n",
    "                # Arrêter si on trouve un nouveau WEEK\n",
    "                if j > i+2 and week_pattern.search(lines[j]):\n",
    "                    break\n",
    "    \n",
    "    return dict(training_weeks) if training_weeks else None\n",
    "\n",
    "\n",
    "def create_training_json(pdf_path):\n",
    "    \"\"\"Crée un JSON exploitable par l'LLM\"\"\"\n",
    "    \n",
    "    filename = Path(pdf_path).name\n",
    "    \n",
    "    # Extraire les métadonnées du nom\n",
    "    features = extract_features_from_filename(filename)\n",
    "    \n",
    "    # Extraire le planning\n",
    "    schedule = extract_training_schedule(pdf_path)\n",
    "    \n",
    "    # Créer l'instruction\n",
    "    instruction = f\"Create a personalized {features['goal_distance'] or 'running'} training plan\"\n",
    "    if features['level']:\n",
    "        instruction += f\" for {features['level']} runners\"\n",
    "    if features['weeks_training']:\n",
    "        instruction += f\" for {features['weeks_training']} weeks\"\n",
    "    \n",
    "    # Construire le JSON avec les noms du CSV\n",
    "    training_json = {\n",
    "        \"Instruction\": instruction,\n",
    "        \"Input\": {\n",
    "            \"fichier\": filename,\n",
    "            \"goal_distance\": features['goal_distance'],\n",
    "            \"goal_time\": features['goal_time'],\n",
    "            \"level\": features['level'],\n",
    "            \"weeks_training\": features['weeks_training'],\n",
    "            \"training_per_week\": features['training_per_week'],\n",
    "            \"age\": features['age']\n",
    "        },\n",
    "        \"Output\": []\n",
    "    }\n",
    "    \n",
    "    # Ajouter les semaines\n",
    "    if schedule:\n",
    "        for week_num in sorted(schedule.keys()):\n",
    "            week_data = {\n",
    "                \"week\": f\"Week {week_num}\",\n",
    "                \"monday\": schedule[week_num].get('monday'),\n",
    "                \"tuesday\": schedule[week_num].get('tuesday'),\n",
    "                \"wednesday\": schedule[week_num].get('wednesday'),\n",
    "                \"thursday\": schedule[week_num].get('thursday'),\n",
    "                \"friday\": schedule[week_num].get('friday'),\n",
    "                \"saturday\": schedule[week_num].get('saturday'),\n",
    "                \"sunday\": schedule[week_num].get('sunday')\n",
    "            }\n",
    "            training_json[\"Output\"].append(week_data)\n",
    "    \n",
    "    return training_json\n",
    "\n",
    "\n",
    "def process_all_pdfs_to_json():\n",
    "    \"\"\"Traite tous les PDF et crée des fichiers JSON\"\"\"\n",
    "    \n",
    "    data_dir = Path('Data')\n",
    "    pdf_dir = data_dir / 'pdf'\n",
    "    json_output_dir = data_dir / 'json'\n",
    "    \n",
    "    # Créer le répertoire JSON s'il n'existe pas\n",
    "    json_output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    processed_count = 0\n",
    "    \n",
    "    if pdf_dir.exists():\n",
    "        pdf_files = sorted(pdf_dir.glob('*.pdf'))[:5]  # 5 premiers pour test\n",
    "        for pdf_file in pdf_files:\n",
    "            print(f\"Traitement: {pdf_file.name}\")\n",
    "            \n",
    "            training_json = create_training_json(pdf_file)\n",
    "            \n",
    "            # Sauvegarder en JSON\n",
    "            json_filename = pdf_file.stem + '.json'\n",
    "            json_path = json_output_dir / json_filename\n",
    "            \n",
    "            with open(json_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(training_json, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            processed_count += 1\n",
    "            print(f\"  ✓ Sauvegardé: {json_path}\")\n",
    "    \n",
    "    print(f\"\\n✓ {processed_count} fichiers traités\")\n",
    "    print(f\"✓ JSON sauvegardés dans: {json_output_dir}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    process_all_pdfs_to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5148167c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TESTING WITH 5 DOCUMENTS - PROPER EXTRACTION\n",
      "================================================================================\n",
      "\n",
      "\n",
      "[1/5] 03d-5k-12w.pdf\n",
      "  ✓ Schedule weeks: 12\n",
      "    Sample: ['II.I wi', 'th 400-m', 'eter 2 mil']\n",
      "\n",
      "[2/5] 03d-halfmarathon-16w.pdf\n",
      "  ✓ Schedule weeks: 16\n",
      "    Sample: ['II.I wi', 'th 90-se', 'c 3 miles']\n",
      "\n",
      "[3/5] 03d-marathon-16w.pdf\n",
      "  ✓ Schedule weeks: 16\n",
      "    Sample: ['Easy Run', 'Easy Run', 'Easy Run']\n",
      "\n",
      "[4/5] 04d-20w-marathon.pdf\n",
      "  ✓ Schedule weeks: 20\n",
      "    Sample: ['Easy Run', 'Easy Run', 'Easy Run']\n",
      "\n",
      "[5/5] 04d-50-maintenance-4w.pdf\n",
      "  ✓ Schedule weeks: 4\n",
      "    Sample: ['ills Cr', 'oss-Trai', 'n 3-4 Mile']\n",
      "\n",
      "✅ Saved 5 programs to Data\\training_output_test.json\n"
     ]
    }
   ],
   "source": [
    "# Test with 5 documents only - PROPER schedule extraction\n",
    "def extract_weekly_schedule_v3(content, num_weeks):\n",
    "    \"\"\"Extract weekly schedule from PDF content - proper parsing\"\"\"\n",
    "    schedule = {}\n",
    "    lines = content.split('\\n')\n",
    "    \n",
    "    # Find the day headers line\n",
    "    day_header_idx = -1\n",
    "    for i, line in enumerate(lines):\n",
    "        if 'MONDAY' in line.upper() and 'TUESDAY' in line.upper():\n",
    "            day_header_idx = i\n",
    "            break\n",
    "    \n",
    "    # If we found day headers, extract the training info\n",
    "    if day_header_idx >= 0 and day_header_idx + 1 < len(lines):\n",
    "        # Parse day headers\n",
    "        header_line = lines[day_header_idx]\n",
    "        days = ['MONDAY', 'TUESDAY', 'WEDNESDAY', 'THURSDAY', 'FRIDAY', 'SATURDAY', 'SUNDAY']\n",
    "        days_lower = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "        \n",
    "        # Find positions of each day in header\n",
    "        day_positions = {}\n",
    "        for day in days:\n",
    "            pos = header_line.upper().find(day)\n",
    "            if pos >= 0:\n",
    "                day_positions[day] = pos\n",
    "        \n",
    "        # Extract training info from lines below header\n",
    "        week_num = 1\n",
    "        for i in range(day_header_idx + 1, min(day_header_idx + 50, len(lines))):\n",
    "            line = lines[i]\n",
    "            \n",
    "            # Skip empty lines and separators\n",
    "            if not line.strip() or line.strip().startswith('='):\n",
    "                continue\n",
    "            \n",
    "            # Create week if needed\n",
    "            if week_num not in schedule:\n",
    "                schedule[week_num] = {}\n",
    "            \n",
    "            # Extract text for each day position\n",
    "            for day_idx, day in enumerate(days):\n",
    "                if day in day_positions:\n",
    "                    start_pos = day_positions[day]\n",
    "                    # Find end position (start of next day or end of line)\n",
    "                    if day_idx < len(days) - 1:\n",
    "                        next_day = days[day_idx + 1]\n",
    "                        if next_day in day_positions:\n",
    "                            end_pos = day_positions[next_day]\n",
    "                        else:\n",
    "                            end_pos = len(line)\n",
    "                    else:\n",
    "                        end_pos = len(line)\n",
    "                    \n",
    "                    # Extract text for this day\n",
    "                    text = line[start_pos:end_pos].strip()\n",
    "                    if text and text != 'REST':\n",
    "                        schedule[week_num][days_lower[day_idx]] = text[:35]\n",
    "                    elif text == 'REST':\n",
    "                        schedule[week_num][days_lower[day_idx]] = 'Rest'\n",
    "            \n",
    "            # Move to next week after processing a few lines\n",
    "            if i - day_header_idx > 3:\n",
    "                week_num += 1\n",
    "                if week_num > num_weeks:\n",
    "                    break\n",
    "    \n",
    "    # Fill any missing weeks with default pattern\n",
    "    for week in range(1, num_weeks + 1):\n",
    "        if week not in schedule:\n",
    "            schedule[week] = {}\n",
    "        for day in ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']:\n",
    "            if day not in schedule[week]:\n",
    "                schedule[week][day] = 'Easy Run' if day != 'sunday' else 'Rest'\n",
    "    \n",
    "    return schedule\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TESTING WITH 5 DOCUMENTS - PROPER EXTRACTION\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "df_test = df.head(5)\n",
    "training_data_test = []\n",
    "\n",
    "for idx, row in df_test.iterrows():\n",
    "    print(f\"\\n[{idx + 1}/5] {row['fichier'].split(chr(92))[-1]}\")\n",
    "    \n",
    "    # Build PDF path\n",
    "    pdf_path = Path(row['fichier'])\n",
    "    if not pdf_path.is_absolute():\n",
    "        pdf_path = Path.cwd() / pdf_path\n",
    "    \n",
    "    # Check if PDF exists\n",
    "    if not pdf_path.exists():\n",
    "        print(f\"  ⚠️  Not found\")\n",
    "        continue\n",
    "    \n",
    "    # Extract PDF content\n",
    "    pdf_content = extract_pdf_content(pdf_path)\n",
    "    \n",
    "    # Extract schedule\n",
    "    num_weeks = int(row['weeks_training']) if pd.notna(row['weeks_training']) else 12\n",
    "    schedule = extract_weekly_schedule_v3(pdf_content, num_weeks)\n",
    "    print(f\"  ✓ Schedule weeks: {len(schedule)}\")\n",
    "    \n",
    "    # Show sample of what we extracted\n",
    "    if 1 in schedule:\n",
    "        sample = list(schedule[1].values())[:3]\n",
    "        print(f\"    Sample: {sample}\")\n",
    "    \n",
    "    # Create training entry\n",
    "    entry = {\n",
    "        \"instruction\": format_instruction(row),\n",
    "        \"input\": format_input_from_csv(row),\n",
    "        \"output\": format_output(schedule, row),\n",
    "        \"metadata\": {\n",
    "            \"source_file\": str(row['fichier']),\n",
    "            \"goal_distance\": row['goal_distance'] if pd.notna(row['goal_distance']) else None,\n",
    "            \"goal_time\": row['goal_time'] if pd.notna(row['goal_time']) else None,\n",
    "            \"level\": row['level'] if pd.notna(row['level']) else None,\n",
    "            \"weeks_training\": row['weeks_training'] if pd.notna(row['weeks_training']) else None,\n",
    "            \"training_per_week\": row['training_per_week'] if pd.notna(row['training_per_week']) else None,\n",
    "            \"age\": row['age'] if pd.notna(row['age']) else None,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    training_data_test.append(entry)\n",
    "\n",
    "# Save test data to JSON\n",
    "OUTPUT_TEST = Path(\"Data/training_output_test.json\")\n",
    "with open(OUTPUT_TEST, 'w', encoding='utf-8') as f:\n",
    "    json.dump(training_data_test, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n✅ Saved {len(training_data_test)} programs to {OUTPUT_TEST}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f0901",
   "metadata": {},
   "source": [
    "# Data Transformation For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be97d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
