{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2560a481",
   "metadata": {},
   "source": [
    "# Data Transformation From pdf to json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7c4625",
   "metadata": {},
   "source": [
    "The goal here is to transform the pdf into a json format to be exploitable by the LLM\n",
    "The Json will be like this : \n",
    "\n",
    "{\n",
    "    \n",
    "        Instruction : a string witch say what want the user\n",
    "\n",
    "        \n",
    "        Input : the equivalence of a sheet with those info : \n",
    "            - The goal distance(None, distance[5km,1miles, etc...])   \n",
    "            - The goal time (None, time[30minutes, below 1hours, etc...])\n",
    "            - The level (None, level[beginner, advanced, ect...])  \n",
    "            - The Number of weeks before the run, or of training (None, weeks[10, 20, 1years, etc...])  \n",
    "            - The Number of training by weeks (None, 1, 2, 4, ect...) \n",
    "            - The age (None, 40, 50, etc...)\n",
    "\n",
    "\n",
    "        Ouput : The equivalence of a 2D sheet with 8 Collums :\n",
    "            - The week (first week, second, ect...)  \n",
    "            - Monday\n",
    "            - Tuesday\n",
    "            - Wednesday\n",
    "            - ....\n",
    "            - Sunday        \n",
    "\n",
    "}\n",
    "\n",
    "None means that there are no info about it (for example None for the age means everyone can do it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f0901",
   "metadata": {},
   "source": [
    "# Data Transformation For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be01299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading augmented training dataset...\n",
      "\n",
      "================================================================================\n",
      "AUGMENTED DATASET STATISTICS\n",
      "================================================================================\n",
      "Total training examples: 26552\n",
      "Dataset generated with 2x augmentation\n",
      "Original weeks: N/A\n",
      "\n",
      "Distribution by level:\n",
      "  general: 16816 (63.3%)\n",
      "  maintenance: 440 (1.7%)\n",
      "  beginner: 3736 (14.1%)\n",
      "  advanced: 4208 (15.8%)\n",
      "  intermediate: 1352 (5.1%)\n",
      "\n",
      "Distribution by goal:\n",
      "  marathon: 18616 (70.1%)\n",
      "  general fitness: 596 (2.2%)\n",
      "  16.1km: 56 (0.2%)\n",
      "  halfmarathon: 5044 (19.0%)\n",
      "  5km: 1400 (5.3%)\n",
      "  10km: 672 (2.5%)\n",
      "  1.6km: 168 (0.6%)\n",
      "\n",
      "Distribution by training days:\n",
      "  4d: 5332 (20.1%)\n",
      "  5d: 13088 (49.3%)\n",
      "  6d: 7560 (28.5%)\n",
      "  7d: 520 (2.0%)\n",
      "  3d: 52 (0.2%)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Filtered examples kept: 26552 / 26552\n",
      "Total instruction examples prepared: 32660\n",
      "\n",
      "Example entry (filtered, week-level format):\n",
      "{\n",
      "  \"instruction\": \"Generate a complete week (2) of a 19-week marathon running program. Training level: general, 6 training days per week. Format attendu: 7 lignes, une par jour, de Lundi à Dimanche, au format 'Jour: Activité'.\",\n",
      "  \"input\": \"Objectif: marathon; Niveau: general; Semaines: 19; Séances/sem: 6; Temps objectif: 3h30m.\",\n",
      "  \"output\": \"Lundi: 8.0km Run\\nMardi: 5.0km Run\\nMercredi: 5 km\\nJeudi: 5.0km Run\\nVendredi: 8.0km Run\\nSamedi: Rest\\nDimanche: 18.0km Long Run\",\n",
      "  \"metadata\": {\n",
      "    \"program\": \"19w-06d-3h30-marathon\",\n",
      "    \"total_weeks\": 19,\n",
      "    \"week\": 2,\n",
      "    \"level\": \"general\",\n",
      "    \"goal\": \"marathon\",\n",
      "    \"training_days\": 6\n",
      "  },\n",
      "  \"weight\": 0.375\n",
      "}\n",
      "\n",
      "Weight stats: min=0.25  max=2.00  mean=1.48\n",
      "Input variants examples:\n",
      "  - Objectif: marathon; Niveau: general; Semaines: 19; Séances/sem: 6; Temps objectif: 3h30m.\n",
      "  - entrainement marathon\n",
      "  - marathon\n",
      "  - entrainement general\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tiktoken\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Load the NEW augmented training dataset\n",
    "print(\"Loading augmented training dataset...\")\n",
    "with open(\"Data/running_week_training_dataset_final_3.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    dataset_full = json.load(file)\n",
    "\n",
    "# Extract training data and metadata\n",
    "training_data = dataset_full.get(\"training_data\", [])\n",
    "metadata = dataset_full.get(\"metadata\", {})\n",
    "stats = metadata.get(\"statistics\", {})\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"AUGMENTED DATASET STATISTICS\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total training examples: {len(training_data)}\")\n",
    "print(f\"Dataset generated with {metadata.get('augmentation_factor', 'N/A')}x augmentation\")\n",
    "print(f\"Original weeks: {metadata.get('total_weeks', 'N/A')}\")\n",
    "\n",
    "print(f\"\\nDistribution by level:\")\n",
    "for level, count in stats.get('by_level', {}).items():\n",
    "    percentage = (count / max(len(training_data), 1)) * 100\n",
    "    print(f\"  {level}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nDistribution by goal:\")\n",
    "for goal, count in stats.get('by_goal', {}).items():\n",
    "    percentage = (count / max(len(training_data), 1)) * 100\n",
    "    print(f\"  {goal}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nDistribution by training days:\")\n",
    "for days, count in stats.get('by_training_days', {}).items():\n",
    "    percentage = (count / max(len(training_data), 1)) * 100\n",
    "    print(f\"  {days}d: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n{'='*80}\\n\")\n",
    "\n",
    "# Data quality filter: keep weeks with at least 2 non-rest days and 7 lines\n",
    "day_pattern = re.compile(r\"^(lundi|mardi|mercredi|jeudi|vendredi|samedi|dimanche)\\s*:\", re.IGNORECASE)\n",
    "rest_pattern = re.compile(r\"\\b(rest|day off)\\b\", re.IGNORECASE)\n",
    "\n",
    "MIN_NON_REST_DAYS = 2\n",
    "MIN_NON_REST_CHARS = 12\n",
    "\n",
    "# We keep richness/diversity as *weights* (sampling), not by duplicating examples.\n",
    "# NOTE: we bias sampling towards weeks that contain at least one \"quality\" session\n",
    "# (Intervals/Tempo/Marathon pace) + Long Run to fight the \"all short runs\" collapse.\n",
    "RICHNESS_BOOST_THRESHOLD = 18\n",
    "DIVERSITY_BOOST_THRESHOLD = 3\n",
    "RICHNESS_WEIGHT_BOOST = 0.5\n",
    "DIVERSITY_WEIGHT_BOOST = 0.8\n",
    "QUALITY_WEIGHT_BOOST = 0.9\n",
    "LONG_RUN_WEIGHT_BOOST = 0.6\n",
    "EASY_HEAVY_PENALTY = 0.35\n",
    "\n",
    "# Input augmentation: generate short / partial user-like queries\n",
    "MAX_INPUT_VARIANTS_PER_ENTRY = 4\n",
    "\n",
    "\n",
    "def normalize_output_text(output_text: str) -> str:\n",
    "    \"\"\"Normalize outputs to reduce label noise.\n",
    "\n",
    "    - Remove template markers (safety)\n",
    "    - Replace 'Easy Run' -> 'Run' (keep 'Long Run')\n",
    "    \"\"\"\n",
    "    if not output_text:\n",
    "        return \"\"\n",
    "    t = output_text.replace(\"<|endoftext|>\", \"\")\n",
    "    # Remove any template delimiters if they ever leaked in\n",
    "    t = re.sub(r\"###\\s*(instruction|input|response)\\s*:\\s*\", \"\", t, flags=re.IGNORECASE)\n",
    "    # Normalize whitespace\n",
    "    t = t.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    # Replace Easy Run by Run (case-insensitive)\n",
    "    t = re.sub(r\"\\bEasy\\s+Run\\b\", \"Run\", t, flags=re.IGNORECASE)\n",
    "    return t.strip()\n",
    "\n",
    "\n",
    "def richness_score(output_text: str) -> float:\n",
    "    lines = [l.strip() for l in output_text.split(\"\\n\") if l.strip()]\n",
    "    non_rest_lines = [l for l in lines[:7] if not rest_pattern.search(l)]\n",
    "    if not non_rest_lines:\n",
    "        return 0.0\n",
    "    return sum(len(l) for l in non_rest_lines) / len(non_rest_lines)\n",
    "\n",
    "\n",
    "def diversity_score(output_text: str) -> int:\n",
    "    lines = [l.strip() for l in output_text.split(\"\\n\") if l.strip()]\n",
    "    non_rest_lines = [l for l in lines[:7] if not rest_pattern.search(l)]\n",
    "    activities = set()\n",
    "    for line in non_rest_lines:\n",
    "        lower = line.lower()\n",
    "        if \"long run\" in lower:\n",
    "            activities.add(\"long\")\n",
    "        if \"interval\" in lower or \"repeats\" in lower:\n",
    "            activities.add(\"interval\")\n",
    "        if \"tempo\" in lower:\n",
    "            activities.add(\"tempo\")\n",
    "        if \"marathon pace\" in lower or \"threshold\" in lower:\n",
    "            activities.add(\"pace\")\n",
    "        if \"recovery\" in lower:\n",
    "            activities.add(\"recovery\")\n",
    "        # After normalization, 'Easy Run' becomes 'Run'\n",
    "        if re.search(r\"\\brun\\b\", lower):\n",
    "            activities.add(\"run\")\n",
    "    return len(activities)\n",
    "\n",
    "\n",
    "def easy_heavy_ratio(output_text: str) -> float:\n",
    "    \"\"\"Fraction of non-rest lines that are plain 'Run' (no long/interval/tempo/pace).\"\"\"\n",
    "    lines = [l.strip() for l in output_text.split(\"\\n\") if l.strip()]\n",
    "    non_rest_lines = [l for l in lines[:7] if not rest_pattern.search(l)]\n",
    "    if not non_rest_lines:\n",
    "        return 0.0\n",
    "\n",
    "    def is_plain_run(line: str) -> bool:\n",
    "        s = line.lower()\n",
    "        if \"long run\" in s:\n",
    "            return False\n",
    "        if any(k in s for k in [\"interval\", \"tempo\", \"marathon pace\", \"threshold\", \"repeats\", \"fartlek\", \"hill\"]):\n",
    "            return False\n",
    "        return \" run\" in s or s.endswith(\"run\")\n",
    "\n",
    "    plain = sum(1 for l in non_rest_lines if is_plain_run(l))\n",
    "    return plain / max(1, len(non_rest_lines))\n",
    "\n",
    "\n",
    "def has_quality_session(output_text: str) -> bool:\n",
    "    s = (output_text or \"\").lower()\n",
    "    return any(k in s for k in [\"interval\", \"tempo\", \"marathon pace\", \"threshold\", \"repeats\", \"fartlek\", \"hill\"])\n",
    "\n",
    "\n",
    "def has_long_run(output_text: str) -> bool:\n",
    "    return \"long run\" in (output_text or \"\").lower()\n",
    "\n",
    "\n",
    "def is_good_example(output_text: str) -> bool:\n",
    "    if not output_text:\n",
    "        return False\n",
    "    lines = [l.strip() for l in output_text.split(\"\\n\") if l.strip()]\n",
    "    if len(lines) < 7:\n",
    "        return False\n",
    "    if sum(1 for l in lines[:7] if day_pattern.search(l)) < 5:\n",
    "        return False\n",
    "    non_rest = [l for l in lines[:7] if not rest_pattern.search(l)]\n",
    "    if len(non_rest) < MIN_NON_REST_DAYS:\n",
    "        return False\n",
    "    avg_len = sum(len(l) for l in non_rest) / len(non_rest)\n",
    "    return avg_len >= MIN_NON_REST_CHARS\n",
    "\n",
    "\n",
    "def parse_profile_from_input(input_text: str) -> dict:\n",
    "    \"\"\"Parse the structured 'Objectif: ...; Niveau: ...;' input into a dict (best-effort).\"\"\"\n",
    "    if not input_text:\n",
    "        return {}\n",
    "    fields = {}\n",
    "    patterns = {\n",
    "        \"goal\": r\"Objectif\\s*:\\s*([^;\\.]+)\",\n",
    "        \"level\": r\"Niveau\\s*:\\s*([^;\\.]+)\",\n",
    "        \"weeks\": r\"Semaines\\s*:\\s*([^;\\.]+)\",\n",
    "        \"sessions\": r\"Séances/sem\\s*:\\s*([^;\\.]+)\",\n",
    "        \"time\": r\"Temps objectif\\s*:\\s*([^;\\.]+)\",\n",
    "    }\n",
    "    for key, pat in patterns.items():\n",
    "        m = re.search(pat, input_text, flags=re.IGNORECASE)\n",
    "        if m:\n",
    "            fields[key] = m.group(1).strip()\n",
    "    return fields\n",
    "\n",
    "\n",
    "def normalize_goal_text(goal: str) -> str:\n",
    "    if not goal:\n",
    "        return \"\"\n",
    "    g = goal.strip().lower()\n",
    "    # unify 10km / 10 km\n",
    "    m = re.match(r\"^(\\d+(?:\\.\\d+)?)\\s*km$\", g)\n",
    "    if m:\n",
    "        return f\"{m.group(1)} km\"\n",
    "    if g == \"semi-marathon\":\n",
    "        return \"semi-marathon\"\n",
    "    return goal.strip()\n",
    "\n",
    "\n",
    "def generate_input_variations(input_text: str) -> list[str]:\n",
    "    \"\"\"Generate short/partial inputs to cover real user queries.\"\"\"\n",
    "    profile = parse_profile_from_input(input_text)\n",
    "    goal = normalize_goal_text(profile.get(\"goal\", \"\"))\n",
    "    level = profile.get(\"level\", \"\").strip() if profile.get(\"level\") else \"\"\n",
    "    weeks = profile.get(\"weeks\", \"\").strip() if profile.get(\"weeks\") else \"\"\n",
    "    sessions = profile.get(\"sessions\", \"\").strip() if profile.get(\"sessions\") else \"\"\n",
    "    goal_time = profile.get(\"time\", \"\").strip() if profile.get(\"time\") else \"\"\n",
    "\n",
    "    variants = []\n",
    "\n",
    "    def add(s: str):\n",
    "        s = (s or \"\").strip()\n",
    "        if not s:\n",
    "            return\n",
    "        s = \" \".join(s.split())\n",
    "        variants.append(s)\n",
    "\n",
    "    # Always keep the original structured input\n",
    "    add(input_text)\n",
    "\n",
    "    # Very short goal/level queries\n",
    "    if goal:\n",
    "        add(f\"entrainement {goal}\")\n",
    "        add(goal)\n",
    "    if level:\n",
    "        add(f\"entrainement {level}\")\n",
    "        add(level)\n",
    "    if goal and level:\n",
    "        add(f\"entrainement {goal} {level}\")\n",
    "        add(f\"plan {goal} niveau {level}\")\n",
    "    if goal and sessions:\n",
    "        add(f\"plan {goal} {sessions} séances par semaine\")\n",
    "    if goal and weeks:\n",
    "        add(f\"plan {goal} {weeks} semaines\")\n",
    "    if weeks and sessions:\n",
    "        add(f\"plan {weeks} semaines {sessions} séances\")\n",
    "    if goal_time and goal:\n",
    "        add(f\"objectif {goal_time} {goal}\")\n",
    "\n",
    "    # Deduplicate, keep order, cap variants\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for v in variants:\n",
    "        k = v.lower()\n",
    "        if k in seen:\n",
    "            continue\n",
    "        seen.add(k)\n",
    "        out.append(v)\n",
    "        if len(out) >= MAX_INPUT_VARIANTS_PER_ENTRY:\n",
    "            break\n",
    "    return out\n",
    "\n",
    "\n",
    "# Normalize outputs before filtering/weighting\n",
    "normalized_training_data = []\n",
    "for e in training_data:\n",
    "    e2 = dict(e)\n",
    "    e2[\"output\"] = normalize_output_text(e.get(\"output\", \"\"))\n",
    "    normalized_training_data.append(e2)\n",
    "\n",
    "filtered_training_data = [e for e in normalized_training_data if is_good_example(e.get(\"output\", \"\"))]\n",
    "print(f\"Filtered examples kept: {len(filtered_training_data)} / {len(training_data)}\")\n",
    "\n",
    "\n",
    "# Compute weights (no duplication): sample more diverse/quality weeks\n",
    "\n",
    "def example_weight(entry: dict) -> float:\n",
    "    out = entry.get(\"output\", \"\") or \"\"\n",
    "    w = 1.0\n",
    "\n",
    "    if richness_score(out) >= RICHNESS_BOOST_THRESHOLD:\n",
    "        w += RICHNESS_WEIGHT_BOOST\n",
    "\n",
    "    if diversity_score(out) >= DIVERSITY_BOOST_THRESHOLD:\n",
    "        w += DIVERSITY_WEIGHT_BOOST\n",
    "\n",
    "    if has_quality_session(out):\n",
    "        w += QUALITY_WEIGHT_BOOST\n",
    "\n",
    "    if has_long_run(out):\n",
    "        w += LONG_RUN_WEIGHT_BOOST\n",
    "\n",
    "    # Penalize weeks that are mostly plain runs (too repetitive)\n",
    "    if easy_heavy_ratio(out) >= 0.65:\n",
    "        w -= EASY_HEAVY_PENALTY\n",
    "\n",
    "    return float(max(0.2, w))\n",
    "\n",
    "\n",
    "# Keep only essential metadata to avoid overfitting on workout_types/noisy fields\n",
    "ESSENTIAL_METADATA_KEYS = {\n",
    "    \"program\",\n",
    "    \"week\",\n",
    "    \"total_weeks\",\n",
    "    \"training_days\",\n",
    "    \"goal\",\n",
    "    \"level\",\n",
    "}\n",
    "\n",
    "\n",
    "def prune_metadata(meta: dict) -> dict:\n",
    "    if not isinstance(meta, dict):\n",
    "        return {}\n",
    "    return {k: meta.get(k) for k in ESSENTIAL_METADATA_KEYS if k in meta}\n",
    "\n",
    "\n",
    "# Transform to instruction format compatible with our model, with INPUT augmentation + weights\n",
    "instruction_data = []\n",
    "for entry in filtered_training_data:\n",
    "    base_weight = example_weight(entry)\n",
    "    input_variants = generate_input_variations(entry.get(\"input\", \"\"))\n",
    "    if not input_variants:\n",
    "        input_variants = [\"\"]\n",
    "\n",
    "    # Split the base weight across variants so we don't overweight a single week\n",
    "    per_variant_weight = base_weight / max(1, len(input_variants))\n",
    "\n",
    "    for v in input_variants:\n",
    "        instruction_data.append({\n",
    "            \"instruction\": entry.get(\"instruction\", \"\"),\n",
    "            \"input\": v,\n",
    "            \"output\": entry.get(\"output\", \"\"),\n",
    "            \"metadata\": prune_metadata(entry.get(\"metadata\", {})),\n",
    "            \"weight\": per_variant_weight,\n",
    "        })\n",
    "\n",
    "print(f\"Total instruction examples prepared: {len(instruction_data)}\")\n",
    "if len(instruction_data) > 0:\n",
    "    # pick a better example with more non-rest days\n",
    "    best_entry = max(\n",
    "        instruction_data,\n",
    "        key=lambda e: sum(1 for l in e['output'].split('\\n') if l.strip() and not rest_pattern.search(l)),\n",
    "    )\n",
    "    print(f\"\\nExample entry (filtered, week-level format):\")\n",
    "    print(json.dumps(best_entry, indent=2, ensure_ascii=False))\n",
    "\n",
    "# Quick sanity checks\n",
    "if instruction_data:\n",
    "    weights = [e.get(\"weight\", 1.0) for e in instruction_data]\n",
    "    print(f\"\\nWeight stats: min={min(weights):.2f}  max={max(weights):.2f}  mean={sum(weights)/len(weights):.2f}\")\n",
    "\n",
    "    # How many outputs still contain 'Easy Run' after normalization?\n",
    "    easy_left = sum(1 for e in instruction_data if \"easy run\" in (e.get(\"output\", \"\").lower()))\n",
    "    print(f\"Outputs still containing 'Easy Run': {easy_left} / {len(instruction_data)}\")\n",
    "\n",
    "    print(\"Input variants examples:\")\n",
    "    for s in generate_input_variations(best_entry.get(\"input\", \"\"))[:MAX_INPUT_VARIANTS_PER_ENTRY]:\n",
    "        print(\"  -\", s)\n",
    "\n",
    "    # Diversity quick stats\n",
    "    ds = [diversity_score(e[\"output\"]) for e in instruction_data[:1000]]\n",
    "    if ds:\n",
    "        print(f\"Diversity score (sample 1k): min={min(ds)} max={max(ds)} mean={sum(ds)/len(ds):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff3b839",
   "metadata": {},
   "source": [
    "# Format Input & Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10830155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example formatted prompt (first 1000 characters):\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Generate a complete week (2) of a 19-week marathon running program. Training level: general, 6 training days per week. Format attendu: 7 lignes, une par jour, de Lundi à Dimanche, au format 'Jour: Activité'.\n",
      "\n",
      "### Input:\n",
      "Objectif: marathon; Niveau: general; Semaines: 19; Séances/sem: 6; Temps objectif: 3h30m.\n",
      "\n",
      "### Response:\n",
      "Lundi: 8.0km Run\n",
      "Mardi: 5.0km Run\n",
      "Mercredi: 5 km\n",
      "Jeudi: 5.0km Run\n",
      "Vendredi: 8.0km Run\n",
      "Samedi: Rest\n",
      "Dimanche: 18.0km Long Run\n",
      "\n",
      "Total length: 573 characters\n"
     ]
    }
   ],
   "source": [
    "def format_input(entry):\n",
    "    \"\"\"Format instruction data in Alpaca-style prompt format\"\"\"\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# Pick a more informative example for preview\n",
    "best_entry = max(\n",
    "    instruction_data,\n",
    "    key=lambda e: sum(1 for l in e[\"output\"].split(\"\\n\") if l.strip() and \"rest\" not in l.lower()),\n",
    ")\n",
    "\n",
    "# Test formatting\n",
    "model_input = format_input(best_entry)\n",
    "desired_response = f\"\\n\\n### Response:\\n{best_entry['output']}\"\n",
    "\n",
    "print(\"Example formatted prompt (first 1000 characters):\")\n",
    "print((model_input + desired_response)[:1000])\n",
    "print(f\"\\nTotal length: {len(model_input + desired_response)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8621c7",
   "metadata": {},
   "source": [
    "# Split Data into Train/Val/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30693c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 32660\n",
      "Training set length: 22862 (70.0%)\n",
      "Validation set length: 4899 (15.0%)\n",
      "Test set length: 4899 (15.0%)\n",
      "Shuffle seed: 42\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Split dataset with random shuffle to reduce ordering bias\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "shuffled = instruction_data.copy()\n",
    "random.shuffle(shuffled)\n",
    "\n",
    "train_portion = int(len(shuffled) * 0.7)   # 70% for training\n",
    "val_portion = int(len(shuffled) * 0.15)    # 15% for validation\n",
    "test_portion = len(shuffled) - train_portion - val_portion  # 15% for testing\n",
    "\n",
    "train_data = shuffled[:train_portion]\n",
    "val_data = shuffled[train_portion:train_portion + val_portion]\n",
    "test_data = shuffled[train_portion + val_portion:]\n",
    "\n",
    "print(f\"Total dataset size: {len(shuffled)}\")\n",
    "print(f\"Training set length: {len(train_data)} ({len(train_data)/len(shuffled)*100:.1f}%)\")\n",
    "print(f\"Validation set length: {len(val_data)} ({len(val_data)/len(shuffled)*100:.1f}%)\")\n",
    "print(f\"Test set length: {len(test_data)} ({len(test_data)/len(shuffled)*100:.1f}%)\")\n",
    "print(f\"Shuffle seed: {seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68a0778",
   "metadata": {},
   "source": [
    "# Create Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e52af5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "\n",
      "Train loader batches:\n",
      "Batch 0: inputs shape torch.Size([2, 157]), targets shape torch.Size([2, 157])\n",
      "Batch 1: inputs shape torch.Size([2, 157]), targets shape torch.Size([2, 157])\n"
     ]
    }
   ],
   "source": [
    "class InstructionDataset(Dataset):\n",
    "    \"\"\"Dataset for instruction-following training\"\"\"\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        self.weights = []\n",
    "        \n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(tokenizer.encode(full_text))\n",
    "            self.weights.append(float(entry.get(\"weight\", 1.0)))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "    ):\n",
    "    \"\"\"Custom collate function for batching sequences\"\"\"\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    \n",
    "    inputs_lst, targets_lst = [], []\n",
    "    \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        \n",
    "        # Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        \n",
    "        # Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "        \n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    \n",
    "    # Convert to tensors and transfer to device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    \n",
    "    return inputs_tensor, targets_tensor\n",
    "\n",
    "\n",
    "# Setup device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Create custom collate function with device\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024,\n",
    "    )\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 2\n",
    "num_workers = 0\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Weighted sampling for training (reduces repetition bias vs duplicating rows)\n",
    "train_sampler = torch.utils.data.WeightedRandomSampler(\n",
    "    weights=torch.tensor(train_dataset.weights, dtype=torch.double),\n",
    "    num_samples=len(train_dataset),\n",
    "    replacement=True,\n",
    "    )\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    sampler=train_sampler,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    "    )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    "    )\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    "    )\n",
    "\n",
    "print(\"\\nTrain loader batches:\")\n",
    "for i, (inputs, targets) in enumerate(train_loader):\n",
    "    if i < 2:\n",
    "        print(f\"Batch {i}: inputs shape {inputs.shape}, targets shape {targets.shape}\")\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab373914",
   "metadata": {},
   "source": [
    "# Load Pretrained GPT-2 Model\n",
    "Note: This section loads a GPT-2 small model (124M) for faster training. You can modify the model size in the configuration below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99adaa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture:\n",
      "SimpleGPT(\n",
      "  (token_embedding): Embedding(50257, 256)\n",
      "  (pos_embedding): Embedding(1024, 256)\n",
      "  (transformer): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (output_layer): Linear(in_features=256, out_features=50257, bias=True)\n",
      ")\n",
      "\n",
      "Total parameters: 28,152,401\n"
     ]
    }
   ],
   "source": [
    "# For this demonstration, we'll create a simple GPT-like model\n",
    "# since we need a minimal model for training on CPU/limited GPU\n",
    "\n",
    "class SimpleGPT(nn.Module):\n",
    "    \"\"\"Simplified GPT model for instruction finetuning\"\"\"\n",
    "    def __init__(self, vocab_size=50257, embedding_dim=256, n_layers=4, n_heads=4, context_length=1024):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.pos_embedding = nn.Embedding(context_length, embedding_dim)\n",
    "        \n",
    "        # Transformer layers\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embedding_dim,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=512,\n",
    "            batch_first=True,\n",
    "            dropout=0.1\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(embedding_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, input_ids):\n",
    "        seq_len = input_ids.size(1)\n",
    "        pos_ids = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)\n",
    "        \n",
    "        token_emb = self.token_embedding(input_ids)\n",
    "        pos_emb = self.pos_embedding(pos_ids)\n",
    "        x = token_emb + pos_emb\n",
    "        \n",
    "        x = self.transformer(x)\n",
    "        logits = self.output_layer(x)\n",
    "        return logits\n",
    "\n",
    "# Initialize model\n",
    "model = SimpleGPT(\n",
    "    vocab_size=50257,\n",
    "    embedding_dim=256,\n",
    "    n_layers=4,\n",
    "    n_heads=4,\n",
    "    context_length=1024\n",
    ")\n",
    "\n",
    "print(f\"Model architecture:\")\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ce67c1",
   "metadata": {},
   "source": [
    "# Training Setup and Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766bb681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating initial losses...\n",
      "Initial Training loss: 10.9805\n",
      "Initial Validation loss: 10.9810\n"
     ]
    }
   ],
   "source": [
    "# Lower weight for Rest tokens to reduce overfitting\n",
    "REST_TOKEN_IDS = set()\n",
    "for token in [\" Rest\", \" rest\", \"Rest\", \"rest\"]:\n",
    "    REST_TOKEN_IDS.update(tokenizer.encode(token))\n",
    "REST_TOKEN_WEIGHT = 0.3\n",
    "VOCAB_SIZE = 50257\n",
    "TOKEN_WEIGHTS = torch.ones(VOCAB_SIZE)\n",
    "for tid in REST_TOKEN_IDS:\n",
    "    if 0 <= tid < VOCAB_SIZE:\n",
    "        TOKEN_WEIGHTS[tid] = REST_TOKEN_WEIGHT\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    \"\"\"Calculate loss for a batch\"\"\"\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    \n",
    "    logits = model(input_batch)\n",
    "    \n",
    "    # Reshape for loss calculation\n",
    "    logits_flat = logits.view(-1, logits.size(-1))\n",
    "    targets_flat = target_batch.view(-1)\n",
    "    \n",
    "    # Use CrossEntropyLoss with ignore_index and lower weight for Rest tokens\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=-100, weight=TOKEN_WEIGHTS.to(device))\n",
    "    loss = loss_fn(logits_flat, targets_flat)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    \"\"\"Calculate average loss over data loader\"\"\"\n",
    "    total_loss = 0.0\n",
    "    total_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (input_batch, target_batch) in enumerate(data_loader):\n",
    "            if num_batches is not None and batch_idx >= num_batches:\n",
    "                break\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "            total_batches += 1\n",
    "    \n",
    "    return total_loss / total_batches if total_batches > 0 else float('inf')\n",
    "\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "# Calculate initial loss\n",
    "print(\"Calculating initial losses...\")\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(f\"Initial Training loss: {train_loss:.4f}\")\n",
    "print(f\"Initial Validation loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3948874d",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34476436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING AVEC LE NOUVEAU DATASET AUGMENTÉ\n",
      "================================================================================\n",
      "Epochs: 4\n",
      "Learning Rate: 0.0001\n",
      "Batch Size: 8\n",
      "Total Training Examples: 22862\n",
      "Training Batches per Epoch: 11431\n",
      "================================================================================\n",
      "\n",
      "Starting training with week generation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4: 100%|██████████| 11431/11431 [37:13<00:00,  5.12it/s, loss=0.018]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: Train Loss=0.2801, Val Loss=0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4: 100%|██████████| 11431/11431 [41:49<00:00,  4.56it/s, loss=0.00236] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: Train Loss=0.0033, Val Loss=0.0004\n",
      "\n",
      "--- Week Generation Evaluation (Epoch 2) ---\n",
      "Week Coherence Score: 54.0%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4: 100%|██████████| 11431/11431 [41:31<00:00,  4.59it/s, loss=9.13e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: Train Loss=0.0011, Val Loss=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4: 100%|██████████| 11431/11431 [41:30<00:00,  4.59it/s, loss=5.37e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: Train Loss=0.0007, Val Loss=0.0001\n",
      "\n",
      "--- Week Generation Evaluation (Epoch 4) ---\n",
      "Week Coherence Score: 65.0%\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Training completed in 169.43 minutes.\n",
      "Final week coherence score: 65.0%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq):\n",
    "    \"\"\"Train the model with validation and week-level generation\"\"\"\n",
    "    train_losses, val_losses = [], []\n",
    "    week_coherence_scores = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        train_batches = 0\n",
    "        \n",
    "        # Training loop\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for input_batch, target_batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "            train_batches += 1\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        avg_train_loss = total_train_loss / train_batches\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        avg_val_loss = calc_loss_loader(val_loader, model, device)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1}: Train Loss={avg_train_loss:.4f}, Val Loss={avg_val_loss:.4f}\")\n",
    "        \n",
    "        # Week generation evaluation (every 2 epochs or at end)\n",
    "        if (epoch + 1) % eval_freq == 0 or epoch == num_epochs - 1:\n",
    "            print(f\"\\n--- Week Generation Evaluation (Epoch {epoch+1}) ---\")\n",
    "            coherence = evaluate_week_generation(model, test_data[:5], tokenizer, device)\n",
    "            week_coherence_scores.append(coherence)\n",
    "            print(f\"Week Coherence Score: {coherence:.1f}%\\n\")\n",
    "    \n",
    "    return train_losses, val_losses, week_coherence_scores\n",
    "\n",
    "\n",
    "def evaluate_week_generation(model, test_samples, tokenizer, device, max_tokens=300):\n",
    "    \"\"\"\n",
    "    Evaluate week generation by checking:\n",
    "    1. Does it generate 7+ lines (roughly one per day)?\n",
    "    2. Does it contain recognizable training terms?\n",
    "    3. Does it have varied activities (not all \"Rest\")?\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    coherence_scores = []\n",
    "    \n",
    "    training_keywords = ['rest', 'run', 'easy', 'tempo', 'interval', 'cross', 'long', 'mile', 'km', 'repeats', 'track', 'warm', 'cool']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for entry in test_samples:\n",
    "            # Generate prediction using the instruction format\n",
    "            prompt = (\n",
    "                f\"Below is an instruction that describes a task. \"\n",
    "                f\"Write a response that appropriately completes the request.\"\n",
    "                f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "            )\n",
    "            if entry.get('input'):\n",
    "                prompt += f\"\\n\\n### Input:\\n{entry['input']}\"\n",
    "            prompt += f\"\\n\\n### Response:\\n\"\n",
    "            \n",
    "            input_ids = tokenizer.encode(prompt)\n",
    "            input_ids = torch.tensor([input_ids[:1024]], dtype=torch.long).to(device)\n",
    "            \n",
    "            # Generate with greedy decoding\n",
    "            output_ids = input_ids.clone()\n",
    "            for _ in range(max_tokens):\n",
    "                logits = model(output_ids)\n",
    "                next_token_logits = logits[0, -1, :]\n",
    "                next_token = torch.argmax(next_token_logits, dim=-1)\n",
    "                output_ids = torch.cat([output_ids, next_token.view(1, 1)], dim=1)\n",
    "                \n",
    "                if next_token.item() == 50256:  # endoftext\n",
    "                    break\n",
    "            \n",
    "            # Decode and evaluate\n",
    "            generated_text = tokenizer.decode(output_ids[0].cpu().numpy())\n",
    "            generated = generated_text.split(\"### Response:\\n\")[-1].strip()\n",
    "            \n",
    "            # Scoring criteria\n",
    "            score = 0\n",
    "            \n",
    "            # 1. Check number of lines (should have ~7 for a week)\n",
    "            lines = [l for l in generated.split('\\n') if l.strip()]\n",
    "            if 5 <= len(lines) <= 9:\n",
    "                score += 30\n",
    "            elif len(lines) >= 3:\n",
    "                score += 15\n",
    "            \n",
    "            # 2. Check for training keywords\n",
    "            text_lower = generated.lower()\n",
    "            keyword_count = sum(1 for kw in training_keywords if kw in text_lower)\n",
    "            score += min(40, keyword_count * 5)  # Max 40 points\n",
    "            \n",
    "            # 3. Check for variety (not all same activity)\n",
    "            if text_lower.count('rest') < len(lines) * 0.8:  # Not all rest\n",
    "                score += 30\n",
    "            \n",
    "            coherence_scores.append(min(100, score))\n",
    "    \n",
    "    return sum(coherence_scores) / len(coherence_scores) if coherence_scores else 0\n",
    "\n",
    "\n",
    "# Training parameters - optimized for 1716 augmented examples\n",
    "num_epochs = 4  # Increased from 3 to better leverage more data\n",
    "learning_rate = 0.0001  # More conservative learning rate for stability\n",
    "batch_size = 8  # Increased for better gradient estimates with more data\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.1)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING AVEC LE NOUVEAU DATASET AUGMENTÉ\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Epochs: {num_epochs}\")\n",
    "print(f\"Learning Rate: {learning_rate}\")\n",
    "print(f\"Batch Size: {batch_size}\")\n",
    "print(f\"Total Training Examples: {len(train_data)}\")\n",
    "print(f\"Training Batches per Epoch: {len(train_loader)}\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"Starting training with week generation evaluation...\")\n",
    "start_time = time.time()\n",
    "\n",
    "train_losses, val_losses, week_coherence_scores = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=2  # Evaluate every 2 epochs\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n",
    "if len(week_coherence_scores) > 0:\n",
    "    print(f\"Final week coherence score: {week_coherence_scores[-1]:.1f}%\")\n",
    "print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c745de1",
   "metadata": {},
   "source": [
    "# Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26a81e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Training Loss: 0.0007\n",
      "Final Validation Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "epochs_range = range(1, num_epochs + 1)\n",
    "plt.plot(epochs_range, train_losses, 'b-o', label='Training Loss')\n",
    "plt.plot(epochs_range, val_losses, 'r-s', label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal Training Loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Final Validation Loss: {val_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921359ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GÉNÉRATION D'UNE SEMAINE COMPLÈTE D'ENTRAÎNEMENT (TOP-K SAMPLING)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Test 1 (dataset)\n",
      "--------------------------------------------------------------------------------\n",
      "📋 PROFIL D'ENTRAÎNEMENT:\n",
      "plan marathon niveau advanced\n",
      "\n",
      "✓ SEMAINE ATTENDUE:\n",
      "Lundi: 7.0km Easy Run\n",
      "Mardi: 5.0km Intervals\n",
      "Mercredi: Pace Run; 7; repetition: 4- 5\n",
      "Jeudi: Rest\n",
      "Vendredi: 10.0km Run\n",
      "Samedi: Rest\n",
      "Dimanche: 32.0km Long Run\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Tokens du prompt: 99\n",
      "\n",
      "🤖 SEMAINE GÉNÉRÉE PAR LE MODÈLE (TOP-K SAMPLING):\n",
      "Lundi: 6 km Easy Run\n",
      "Mardi: 5 km Easy Run\n",
      "Mercredi: 7 km Easy Run\n",
      "Jeudi: Rest\n",
      "Vendredi: Rest\n",
      "Samedi: 8 km Easy Run\n",
      "Dimanche: Rest\n",
      "\n",
      "📊 COMPARAISON:\n",
      "--------------------------------------------------------------------------------\n",
      "Nombre de jours attendus: 7\n",
      "Nombre de jours générés: 7\n",
      "\n",
      "Jours attendus:\n",
      "  Lundi: 7.0km Easy Run\n",
      "  Mardi: 5.0km Intervals\n",
      "  Mercredi: Pace Run; 7; repetition: 4- 5\n",
      "  Jeudi: Rest\n",
      "  Vendredi: 10.0km Run\n",
      "  Samedi: Rest\n",
      "  Dimanche: 32.0km Long Run\n",
      "\n",
      "Jours générés:\n",
      "  Lundi: 6 km Easy Run\n",
      "  Mardi: 5 km Easy Run\n",
      "  Mercredi: 7 km Easy Run\n",
      "  Jeudi: Rest\n",
      "  Vendredi: Rest\n",
      "  Samedi: 8 km Easy Run\n",
      "  Dimanche: Rest\n",
      "\n",
      "ANALYSE DE LA QUALITÉ:\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Lignes avec format jour valide: 7/7\n",
      "✓ Tokens cassés détectés: 0\n",
      "✓ Termes d'entraînement trouvés: 4/10\n",
      "\n",
      "📈 SCORE DE QUALITÉ: 82.0/100\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Test 2 (dataset)\n",
      "--------------------------------------------------------------------------------\n",
      "📋 PROFIL D'ENTRAÎNEMENT:\n",
      "general\n",
      "\n",
      "✓ SEMAINE ATTENDUE:\n",
      "Lundi: Rest\n",
      "Mardi: 7 km Run\n",
      "Mercredi: 6.4 km Easy Run\n",
      "Jeudi: 14.5 km Intervals\n",
      "Vendredi: 0-4.8 km Easy Run\n",
      "Samedi: Rest\n",
      "Dimanche: Rest\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Tokens du prompt: 87\n",
      "\n",
      "🤖 SEMAINE GÉNÉRÉE PAR LE MODÈLE (TOP-K SAMPLING):\n",
      "Lundi: 12 km Recovery Run### Response: 12 km Marathon Pace km Run\n",
      "Mardi: 6 km Easy Run\n",
      "Mercredi: 5 km Easy Run\n",
      "Jeudi: 7 km Easy Run\n",
      "Vendredi: Rest\n",
      "Samedi: Rest\n",
      "Dimanche: Rest\n",
      "\n",
      "📊 COMPARAISON:\n",
      "--------------------------------------------------------------------------------\n",
      "Nombre de jours attendus: 7\n",
      "Nombre de jours générés: 7\n",
      "\n",
      "Jours attendus:\n",
      "  Lundi: Rest\n",
      "  Mardi: 7 km Run\n",
      "  Mercredi: 6.4 km Easy Run\n",
      "  Jeudi: 14.5 km Intervals\n",
      "  Vendredi: 0-4.8 km Easy Run\n",
      "  Samedi: Rest\n",
      "  Dimanche: Rest\n",
      "\n",
      "Jours générés:\n",
      "  Lundi: 12 km Recovery Run### Response: 12 km Marathon Pace km Run\n",
      "  Mardi: 6 km Easy Run\n",
      "  Mercredi: 5 km Easy Run\n",
      "  Jeudi: 7 km Easy Run\n",
      "  Vendredi: Rest\n",
      "  Samedi: Rest\n",
      "  Dimanche: Rest\n",
      "\n",
      "ANALYSE DE LA QUALITÉ:\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Lignes avec format jour valide: 7/7\n",
      "✓ Tokens cassés détectés: 1\n",
      "✓ Termes d'entraînement trouvés: 4/10\n",
      "\n",
      "📈 SCORE DE QUALITÉ: 77.0/100\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Test 3 (custom)\n",
      "--------------------------------------------------------------------------------\n",
      "📋 PROFIL D'ENTRAÎNEMENT:\n",
      "Objectif: 10 km; Niveau: débutant; Semaines: 8; Séances/sem: 3; Temps objectif: 55 min.\n",
      "\n",
      "Tokens du prompt: 129\n",
      "\n",
      "🤖 SEMAINE GÉNÉRÉE PAR LE MODÈLE (TOP-K SAMPLING):\n",
      "Lundi: 6 km Easy Run\n",
      "Mardi: 5 km Easy Run\n",
      "Mercredi: 7 km Easy Run\n",
      "Jeudi: Rest\n",
      "Vendredi: Rest\n",
      "Samedi: Rest\n",
      "Dimanche: Rest\n",
      "\n",
      "📊 COMPARAISON:\n",
      "--------------------------------------------------------------------------------\n",
      "Nombre de jours générés: 7\n",
      "\n",
      "Jours générés:\n",
      "  Lundi: 6 km Easy Run\n",
      "  Mardi: 5 km Easy Run\n",
      "  Mercredi: 7 km Easy Run\n",
      "  Jeudi: Rest\n",
      "  Vendredi: Rest\n",
      "  Samedi: Rest\n",
      "  Dimanche: Rest\n",
      "\n",
      "ANALYSE DE LA QUALITÉ:\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Lignes avec format jour valide: 7/7\n",
      "✓ Tokens cassés détectés: 0\n",
      "✓ Termes d'entraînement trouvés: 4/10\n",
      "\n",
      "📈 SCORE DE QUALITÉ: 82.0/100\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Test 4 (custom)\n",
      "--------------------------------------------------------------------------------\n",
      "📋 PROFIL D'ENTRAÎNEMENT:\n",
      "Objectif: semi-marathon; Niveau: intermédiaire; Semaines: 12; Séances/sem: 4; Temps objectif: 1h50.\n",
      "\n",
      "Tokens du prompt: 135\n",
      "\n",
      "🤖 SEMAINE GÉNÉRÉE PAR LE MODÈLE (TOP-K SAMPLING):\n",
      "Lundi: 6 km Easy Run\n",
      "Mardi: 5 km Easy Run\n",
      "Mercredi: 7 km Easy Run\n",
      "Jeudi: Rest\n",
      "Vendredi: Rest\n",
      "Samedi: 25 minutes Easy Run\n",
      "Dimanche: Rest\n",
      "\n",
      "📊 COMPARAISON:\n",
      "--------------------------------------------------------------------------------\n",
      "Nombre de jours générés: 7\n",
      "\n",
      "Jours générés:\n",
      "  Lundi: 6 km Easy Run\n",
      "  Mardi: 5 km Easy Run\n",
      "  Mercredi: 7 km Easy Run\n",
      "  Jeudi: Rest\n",
      "  Vendredi: Rest\n",
      "  Samedi: 25 minutes Easy Run\n",
      "  Dimanche: Rest\n",
      "\n",
      "ANALYSE DE LA QUALITÉ:\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Lignes avec format jour valide: 7/7\n",
      "✓ Tokens cassés détectés: 0\n",
      "✓ Termes d'entraînement trouvés: 4/10\n",
      "\n",
      "📈 SCORE DE QUALITÉ: 82.0/100\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Test 5 (custom)\n",
      "--------------------------------------------------------------------------------\n",
      "📋 PROFIL D'ENTRAÎNEMENT:\n",
      "Objectif: marathon; Niveau: avancé; Semaines: 16; Séances/sem: 5; Temps objectif: 3h30.\n",
      "\n",
      "Tokens du prompt: 129\n",
      "\n",
      "🤖 SEMAINE GÉNÉRÉE PAR LE MODÈLE (TOP-K SAMPLING):\n",
      "Lundi: 6 km Easy Run\n",
      "Mardi: 5 km Easy Run\n",
      "Mercredi: 7 km Easy Run\n",
      "Jeudi: 8 km Easy Run\n",
      "Vendredi: Rest\n",
      "Samedi: 22 x 75 km\n",
      "Dimanche: Rest\n",
      "\n",
      "📊 COMPARAISON:\n",
      "--------------------------------------------------------------------------------\n",
      "Nombre de jours générés: 7\n",
      "\n",
      "Jours générés:\n",
      "  Lundi: 6 km Easy Run\n",
      "  Mardi: 5 km Easy Run\n",
      "  Mercredi: 7 km Easy Run\n",
      "  Jeudi: 8 km Easy Run\n",
      "  Vendredi: Rest\n",
      "  Samedi: 22 x 75 km\n",
      "  Dimanche: Rest\n",
      "\n",
      "ANALYSE DE LA QUALITÉ:\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Lignes avec format jour valide: 7/7\n",
      "✓ Tokens cassés détectés: 0\n",
      "✓ Termes d'entraînement trouvés: 4/10\n",
      "\n",
      "📈 SCORE DE QUALITÉ: 82.0/100\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GÉNÉRATION D'UNE SEMAINE COMPLÈTE D'ENTRAÎNEMENT (TOP-K SAMPLING)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "\n",
    "def apply_repetition_penalty(logits, generated_ids, penalty=1.2):\n",
    "    if penalty == 1.0 or generated_ids.numel() == 0:\n",
    "        return logits\n",
    "    unique_ids = torch.unique(generated_ids)\n",
    "    logits[unique_ids] = logits[unique_ids] / penalty\n",
    "    return logits\n",
    "\n",
    "\n",
    "def generate_with_sampling(\n",
    "    model,\n",
    "    prompt_ids,\n",
    "    tokenizer,\n",
    "    device,\n",
    "    max_tokens=200,\n",
    "    top_k=50,\n",
    "    temperature=0.7,\n",
    "    stop_token=50256,\n",
    "    repetition_penalty=1.2,\n",
    "):\n",
    "    \"\"\"Generate text using top-k sampling with repetition penalty\"\"\"\n",
    "    model.eval()\n",
    "    output_ids = prompt_ids.clone()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_tokens):\n",
    "            logits = model(output_ids)\n",
    "            next_token_logits = logits[0, -1, :] / temperature\n",
    "            next_token_logits = apply_repetition_penalty(\n",
    "                next_token_logits, output_ids[0], penalty=repetition_penalty\n",
    "            )\n",
    "\n",
    "            top_k_logits, top_k_indices = torch.topk(next_token_logits, top_k)\n",
    "            top_k_probs = torch.softmax(top_k_logits, dim=-1)\n",
    "            sampled_idx = torch.multinomial(top_k_probs, 1)\n",
    "            next_token = top_k_indices[sampled_idx]\n",
    "            output_ids = torch.cat([output_ids, next_token.view(1, 1)], dim=1)\n",
    "\n",
    "            if next_token.item() == stop_token:\n",
    "                break\n",
    "\n",
    "    return output_ids\n",
    "\n",
    "\n",
    "def build_prompt(instruction_text, input_text):\n",
    "    prompt_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{instruction_text}\"\n",
    "    )\n",
    "    if input_text:\n",
    "        prompt_text += f\"\\n\\n### Input:\\n{input_text}\"\n",
    "    prompt_text += f\"\\n\\n### Response:\\n\"\n",
    "    return prompt_text\n",
    "\n",
    "\n",
    "def parse_training_days(input_text: str):\n",
    "    if not input_text:\n",
    "        return None\n",
    "    patterns = [\n",
    "        r\"séances/sem\\s*:\\s*(\\d+)\",\n",
    "        r\"seances/sem\\s*:\\s*(\\d+)\",\n",
    "        r\"sessions/sem\\s*:\\s*(\\d+)\",\n",
    "        r\"entrainements/sem\\s*:\\s*(\\d+)\",\n",
    "        r\"entrainements par semaine\\s*:\\s*(\\d+)\",\n",
    "    ]\n",
    "    for p in patterns:\n",
    "        m = re.search(p, input_text, flags=re.IGNORECASE)\n",
    "        if m:\n",
    "            try:\n",
    "                return int(m.group(1))\n",
    "            except ValueError:\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def normalize_generation_text(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    t = text.replace(\"<|endoftext|>\", \"\")\n",
    "    # Normalize newline markers (some models leak literal \\n or /n)\n",
    "    t = t.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    t = t.replace(\"\\\\n\", \"\\n\")\n",
    "    t = re.sub(r\"(?<!\\\\)/n\", \"\\n\", t)\n",
    "    return t.strip()\n",
    "\n",
    "\n",
    "def clean_content(content: str) -> str:\n",
    "    c = (content or \"\").strip()\n",
    "    if not c:\n",
    "        return \"Rest\"\n",
    "\n",
    "    # Hard-cut any leaked prompt delimiter\n",
    "    if \"###\" in c:\n",
    "        c = c.split(\"###\", 1)[0].strip()\n",
    "\n",
    "    c = re.sub(r\"###\\s*(instruction|input|response)\\s*:\\s*\", \"\", c, flags=re.IGNORECASE)\n",
    "    c = re.sub(r\"[\\\\/]+\", \" \", c)\n",
    "    c = re.sub(r\"\\bmin\\s*:\\s*\", \"min \", c, flags=re.IGNORECASE)\n",
    "    c = re.sub(r\"\\s+\", \" \", c).strip(\" -;,\")\n",
    "    c = re.sub(r\"(\\d)(km|mile|miles|min)\", r\"\\1 \\2\", c, flags=re.IGNORECASE)\n",
    "\n",
    "    # Replace Easy Run -> Run (keep Long Run)\n",
    "    c = re.sub(r\"\\bEasy\\s+Run\\b\", \"Run\", c, flags=re.IGNORECASE)\n",
    "\n",
    "    if c in {\"-\", \"/\"}:\n",
    "        return \"Rest\"\n",
    "\n",
    "    # Fix weird duplication like \"Marathon Pace km Run\"\n",
    "    c = re.sub(r\"\\b(Marathon Pace)\\s+km\\b\", r\"\\1\", c, flags=re.IGNORECASE)\n",
    "\n",
    "    # Guardrail: absurd repeats like \"22 x 75 km\"\n",
    "    m_rep = re.match(r\"^(\\d+)\\s*x\\s*(\\d+(?:\\.\\d+)?)\\s*km$\", c, flags=re.IGNORECASE)\n",
    "    if m_rep:\n",
    "        reps = int(m_rep.group(1))\n",
    "        dist = float(m_rep.group(2))\n",
    "        if reps >= 12 or dist >= 5:\n",
    "            return \"Intervals\"\n",
    "\n",
    "    # If only a time is present, assume run\n",
    "    if re.match(r\"^\\d+(?:\\.\\d+)?\\s*min(utes)?$\", c, flags=re.IGNORECASE):\n",
    "        return c + \" Run\"\n",
    "\n",
    "    # If only distance is present, assume run\n",
    "    if re.match(r\"^\\d+(?:\\.\\d+)?\\s*(km|mile|miles)$\", c, flags=re.IGNORECASE):\n",
    "        return c + \" Run\"\n",
    "\n",
    "    # If distance + activity but missing unit, add km\n",
    "    m = re.match(\n",
    "        r\"^(\\d+(?:\\.\\d+)?)\\s*(run|long run|intervals|tempo|recovery|marathon pace)$\",\n",
    "        c,\n",
    "        flags=re.IGNORECASE,\n",
    "    )\n",
    "    if m and \"km\" not in c.lower() and \"mile\" not in c.lower() and \"min\" not in c.lower():\n",
    "        num = m.group(1)\n",
    "        label = m.group(2).title()\n",
    "        return f\"{num} km {label}\"\n",
    "\n",
    "    return c\n",
    "\n",
    "\n",
    "def ensure_minimum_diversity(lines, target_rest=None):\n",
    "    if len(lines) != 7:\n",
    "        return lines\n",
    "\n",
    "    training_days = None\n",
    "    if target_rest is not None:\n",
    "        training_days = max(0, 7 - int(target_rest))\n",
    "\n",
    "    def is_rest(line: str) -> bool:\n",
    "        return line.lower().endswith(\": rest\")\n",
    "\n",
    "    def replace_rest(label: str) -> bool:\n",
    "        for i in range(len(lines)):\n",
    "            if is_rest(lines[i]):\n",
    "                lines[i] = f\"{lines[i].split(':',1)[0]}: {label}\"\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def replace_any(predicate, label: str) -> bool:\n",
    "        # replace first non-rest that matches predicate\n",
    "        for i in range(len(lines)):\n",
    "            if is_rest(lines[i]):\n",
    "                continue\n",
    "            if \":\" not in lines[i]:\n",
    "                continue\n",
    "            day, content = lines[i].split(\":\", 1)\n",
    "            if predicate(content.strip()):\n",
    "                lines[i] = f\"{day}: {label}\"\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    non_rest = [l for l in lines if not is_rest(l)]\n",
    "    has_long = any(\"long run\" in l.lower() for l in non_rest)\n",
    "    has_quality = any(\n",
    "        any(k in l.lower() for k in [\"interval\", \"tempo\", \"marathon pace\", \"threshold\", \"repeats\", \"fartlek\", \"hill\"])\n",
    "        for l in non_rest\n",
    "    )\n",
    "\n",
    "    # If user has >=2 sessions/week, enforce a Long Run\n",
    "    if training_days is None or training_days >= 2:\n",
    "        if not has_long:\n",
    "            if not replace_rest(\"12 km Long Run\"):\n",
    "                # replace a plain Run if no rest slots\n",
    "                replace_any(lambda c: (\"run\" in c.lower()) and (\"long run\" not in c.lower()), \"12 km Long Run\")\n",
    "\n",
    "    # If user has >=3 sessions/week, enforce at least 1 quality session\n",
    "    if training_days is None or training_days >= 3:\n",
    "        if not has_quality:\n",
    "            if not replace_rest(\"6 km Intervals\"):\n",
    "                # replace a plain Run (avoid long run)\n",
    "                replace_any(\n",
    "                    lambda c: (\"run\" in c.lower()) and (\"long run\" not in c.lower()),\n",
    "                    \"6 km Intervals\",\n",
    "                )\n",
    "\n",
    "    # Always ensure at least one generic Run if everything is Rest\n",
    "    has_run = any(\" run\" in l.lower() for l in non_rest)\n",
    "    if not has_run:\n",
    "        replace_rest(\"6 km Run\")\n",
    "\n",
    "    return lines\n",
    "\n",
    "\n",
    "def diversify_distances(lines):\n",
    "    distance_pattern = re.compile(r\"^(\\d+(?:\\.\\d+)?)\\s*km\\b\", re.IGNORECASE)\n",
    "    allowed_activity = re.compile(r\"\\b(run|intervals|tempo|recovery)\\b\", re.IGNORECASE)\n",
    "    available = [5, 6, 7, 8, 10]\n",
    "    used = set()\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.lower().endswith(\": rest\"):\n",
    "            continue\n",
    "        if \":\" not in line:\n",
    "            continue\n",
    "        day, content = line.split(\":\", 1)\n",
    "        content = content.strip()\n",
    "        m = distance_pattern.match(content)\n",
    "        if not m:\n",
    "            continue\n",
    "        if not allowed_activity.search(content) and (\"long run\" not in content.lower()):\n",
    "            used.add(float(m.group(1)))\n",
    "            continue\n",
    "        dist = float(m.group(1))\n",
    "        if dist in used:\n",
    "            new_dist = next((d for d in available if d not in used), None)\n",
    "            if new_dist is None:\n",
    "                new_dist = dist\n",
    "            content = distance_pattern.sub(f\"{new_dist} km\", content, count=1)\n",
    "            lines[i] = f\"{day}: {content}\"\n",
    "            used.add(float(new_dist))\n",
    "        else:\n",
    "            used.add(dist)\n",
    "    return lines\n",
    "\n",
    "\n",
    "def enforce_week_structure(text, max_rest=3, target_rest=None):\n",
    "    text = normalize_generation_text(text)\n",
    "\n",
    "    lines = [l.strip() for l in text.split(\"\\n\") if l.strip()]\n",
    "    day_order = [\"lundi\", \"mardi\", \"mercredi\", \"jeudi\", \"vendredi\", \"samedi\", \"dimanche\"]\n",
    "    day_labels = [\"Lundi\", \"Mardi\", \"Mercredi\", \"Jeudi\", \"Vendredi\", \"Samedi\", \"Dimanche\"]\n",
    "\n",
    "    day_map = {}\n",
    "    for line in lines:\n",
    "        lower = line.lower()\n",
    "        for day in day_order:\n",
    "            if lower.startswith(day):\n",
    "                content = line.split(\":\", 1)[1].strip() if \":\" in line else \"Rest\"\n",
    "                content = clean_content(content)\n",
    "                if not content:\n",
    "                    content = \"Rest\"\n",
    "                if day not in day_map:\n",
    "                    day_map[day] = content\n",
    "                break\n",
    "\n",
    "    output_lines = []\n",
    "    for day, label in zip(day_order, day_labels):\n",
    "        content = day_map.get(day, \"Rest\")\n",
    "        output_lines.append(f\"{label}: {content}\")\n",
    "\n",
    "    if target_rest is None:\n",
    "        target_rest = max_rest\n",
    "\n",
    "    rest_count = sum(1 for l in output_lines if l.lower().endswith(\": rest\"))\n",
    "    if rest_count > target_rest:\n",
    "        for i in range(len(output_lines)):\n",
    "            if rest_count <= target_rest:\n",
    "                break\n",
    "            if output_lines[i].lower().endswith(\": rest\"):\n",
    "                output_lines[i] = output_lines[i].split(\":\", 1)[0] + \": 6 km Run\"\n",
    "                rest_count -= 1\n",
    "    elif rest_count < target_rest:\n",
    "        for i in range(len(output_lines)):\n",
    "            if rest_count >= target_rest:\n",
    "                break\n",
    "            lower = output_lines[i].lower()\n",
    "            if any(k in lower for k in [\"long run\", \"interval\", \"tempo\", \"marathon pace\"]):\n",
    "                continue\n",
    "            if \":\" in output_lines[i] and not output_lines[i].lower().endswith(\": rest\"):\n",
    "                output_lines[i] = output_lines[i].split(\":\", 1)[0] + \": Rest\"\n",
    "                rest_count += 1\n",
    "\n",
    "    output_lines = ensure_minimum_diversity(output_lines, target_rest=target_rest)\n",
    "    output_lines = diversify_distances(output_lines)\n",
    "\n",
    "    return \"\\n\".join(output_lines)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Cas de test: mélange d'exemples du dataset + inputs personnalisés\n",
    "fallback_instruction = test_data[0].get(\n",
    "    \"instruction\", \"Génère un plan d'entraînement de course à pied sur 1 semaine.\"\n",
    ")\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        \"label\": \"Test 1 (dataset)\",\n",
    "        \"input\": test_data[0].get(\"input\", \"\"),\n",
    "        \"expected\": test_data[0].get(\"output\", None),\n",
    "        \"instruction\": test_data[0].get(\"instruction\", fallback_instruction),\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Test 2 (dataset)\",\n",
    "        \"input\": test_data[1].get(\"input\", \"\"),\n",
    "        \"expected\": test_data[1].get(\"output\", None),\n",
    "        \"instruction\": test_data[1].get(\"instruction\", fallback_instruction),\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Test 3 (custom)\",\n",
    "        \"input\": \"Objectif: 10 km; Niveau: débutant; Semaines: 8; Séances/sem: 3; Temps objectif: 55 min.\",\n",
    "        \"expected\": None,\n",
    "        \"instruction\": fallback_instruction,\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Test 4 (custom)\",\n",
    "        \"input\": \"Objectif: semi-marathon; Niveau: intermédiaire; Semaines: 12; Séances/sem: 4; Temps objectif: 1h50.\",\n",
    "        \"expected\": None,\n",
    "        \"instruction\": fallback_instruction,\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Test 5 (custom)\",\n",
    "        \"input\": \"Objectif: marathon; Niveau: avancé; Semaines: 16; Séances/sem: 5; Temps objectif: 3h30.\",\n",
    "        \"expected\": None,\n",
    "        \"instruction\": fallback_instruction,\n",
    "    },\n",
    "]\n",
    "\n",
    "for case in test_cases:\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(f\"{case['label']}\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"📋 PROFIL D'ENTRAÎNEMENT:\\n{case['input']}\\n\")\n",
    "    if case.get(\"expected\"):\n",
    "        print(f\"✓ SEMAINE ATTENDUE:\\n{case['expected']}\\n\")\n",
    "        print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "    prompt = build_prompt(case.get(\"instruction\", fallback_instruction), case.get(\"input\", \"\"))\n",
    "    input_ids = tokenizer.encode(prompt)\n",
    "    print(f\"Tokens du prompt: {len(input_ids)}\\n\")\n",
    "\n",
    "    input_ids_tensor = torch.tensor([input_ids[:1024]], dtype=torch.long).to(device)\n",
    "    output_ids = generate_with_sampling(\n",
    "        model,\n",
    "        input_ids_tensor,\n",
    "        tokenizer,\n",
    "        device,\n",
    "        max_tokens=200,\n",
    "        top_k=50,\n",
    "        temperature=0.7,\n",
    "        repetition_penalty=1.2,\n",
    "    )\n",
    "\n",
    "    full_text = tokenizer.decode(output_ids[0].cpu().numpy())\n",
    "    if \"### Response:\\n\" in full_text:\n",
    "        generated_week = full_text.split(\"### Response:\\n\")[-1].strip()\n",
    "    else:\n",
    "        generated_week = full_text[-400:]\n",
    "\n",
    "    training_days = parse_training_days(case.get(\"input\", \"\"))\n",
    "    target_rest = None\n",
    "    if training_days and 1 <= training_days <= 7:\n",
    "        target_rest = max(0, 7 - training_days)\n",
    "\n",
    "    generated_week = enforce_week_structure(generated_week, max_rest=3, target_rest=target_rest)\n",
    "\n",
    "    print(f\"🤖 SEMAINE GÉNÉRÉE PAR LE MODÈLE (TOP-K SAMPLING):\\n{generated_week}\\n\")\n",
    "\n",
    "    # Évaluation basique\n",
    "    expected_lines = case.get(\"expected\", \"\").strip().split(\"\\n\") if case.get(\"expected\") else []\n",
    "    generated_lines = generated_week.strip().split(\"\\n\")\n",
    "\n",
    "    print(\"📊 COMPARAISON:\")\n",
    "    print(\"-\" * 80)\n",
    "    if expected_lines:\n",
    "        print(f\"Nombre de jours attendus: {len(expected_lines)}\")\n",
    "    print(f\"Nombre de jours générés: {len(generated_lines)}\\n\")\n",
    "\n",
    "    if expected_lines:\n",
    "        print(\"Jours attendus:\")\n",
    "        for line in expected_lines[:7]:\n",
    "            print(f\"  {line}\")\n",
    "        print(\"\")\n",
    "\n",
    "    print(\"Jours générés:\")\n",
    "    for line in generated_lines[:7]:\n",
    "        print(f\"  {line}\")\n",
    "\n",
    "    print(\"\\nANALYSE DE LA QUALITÉ:\")\n",
    "    print(\"-\" * 80)\n",
    "    day_names = ['lundi', 'mardi', 'mercredi', 'jeudi', 'vendredi', 'samedi', 'dimanche']\n",
    "    valid_format = sum(1 for line in generated_lines[:7] if any(day.lower() in line.lower() for day in day_names))\n",
    "    print(f\"✓ Lignes avec format jour valide: {valid_format}/7\")\n",
    "    broken_tokens = generated_week.count('ff') + generated_week.count('###')\n",
    "    print(f\"✓ Tokens cassés détectés: {broken_tokens}\")\n",
    "\n",
    "    training_terms = ['rest', 'run', 'tempo', 'long', 'miles', 'km', 'cross', 'hills', 'interval', 'marathon pace']\n",
    "    found_terms = sum(1 for term in training_terms if term.lower() in generated_week.lower())\n",
    "    print(f\"✓ Termes d'entraînement trouvés: {found_terms}/{len(training_terms)}\")\n",
    "\n",
    "    quality_score = (valid_format / 7 * 40) + max(0, 30 - broken_tokens * 5) + (found_terms / len(training_terms) * 30)\n",
    "    print(f\"\\n📈 SCORE DE QUALITÉ: {quality_score:.1f}/100\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c2f9ca",
   "metadata": {},
   "source": [
    "# Save Model and Test Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d94a18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created output directory structure:\n",
      "   📁 output\\model\n",
      "   📁 output\\json\n",
      "\n",
      "✅ Model saved as output\\model\\running_plan_finetuned_model_3.pth\n",
      "✅ Training metrics saved as output\\json\\training_metrics_3.json\n",
      "✅ Test data results saved as output\\json\\test_data_results_3.json\n",
      "\n",
      "📦 All outputs saved in:\n",
      "   Models:  C:\\Users\\rerel\\OneDrive\\Bureau\\Esiee\\Esiee\\E5\\LLM\\Projet\\output\\model\n",
      "   JSON:    C:\\Users\\rerel\\OneDrive\\Bureau\\Esiee\\Esiee\\E5\\LLM\\Projet\\output\\json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create output directory structure\n",
    "output_dir = Path(\"output\")\n",
    "model_dir = output_dir / \"model\"\n",
    "json_dir = output_dir / \"json\"\n",
    "\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "json_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"✅ Created output directory structure:\")\n",
    "print(f\"   📁 {model_dir}\")\n",
    "print(f\"   📁 {json_dir}\\n\")\n",
    "\n",
    "# Save model weights\n",
    "model_save_path = model_dir / \"running_plan_finetuned_model_3.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"✅ Model saved as {model_save_path}\")\n",
    "\n",
    "# Save training metrics\n",
    "metrics = {\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"train_losses\": train_losses,\n",
    "    \"val_losses\": val_losses,\n",
    "    \"total_programs\": len(instruction_data),\n",
    "    \"train_size\": len(train_data),\n",
    "    \"val_size\": len(val_data),\n",
    "    \"test_size\": len(test_data),\n",
    "}\n",
    "\n",
    "metrics_save_path = json_dir / \"training_metrics_3.json\"\n",
    "with open(metrics_save_path, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"✅ Training metrics saved as {metrics_save_path}\")\n",
    "\n",
    "# Save test data with metadata\n",
    "test_results = {\n",
    "    \"test_programs\": test_data,\n",
    "    \"metrics\": metrics\n",
    "}\n",
    "\n",
    "results_save_path = json_dir / \"test_data_results_3.json\"\n",
    "with open(results_save_path, \"w\") as f:\n",
    "    json.dump(test_results, f, indent=2)\n",
    "\n",
    "print(f\"✅ Test data results saved as {results_save_path}\")\n",
    "\n",
    "print(f\"\\n📦 All outputs saved in:\")\n",
    "print(f\"   Models:  {model_dir.resolve()}\")\n",
    "print(f\"   JSON:    {json_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f84f68",
   "metadata": {},
   "source": [
    "# Summary and Next Steps\n",
    "\n",
    "## Training Completed! ✓\n",
    "\n",
    "The model has been fine-tuned on running training schedules using instruction following methodology similar to ch07.ipynb.\n",
    "\n",
    "### Key Outputs:\n",
    "- **Model weights**: `running_plan_finetuned_model.pth`\n",
    "- **Training metrics**: `training_metrics.json`\n",
    "- **Test results**: `test_data_results.json`\n",
    "\n",
    "### Next Steps:\n",
    "1. **Evaluate model**: Generate running schedules from test user profiles\n",
    "2. **Improve performance**: Increase training epochs, use larger model, or augment data\n",
    "3. **Production deployment**: Create a web interface or API for users\n",
    "4. **Preference tuning**: Use DPO to align model with user preferences (see ch07 bonus)\n",
    "\n",
    "### Model Capabilities:\n",
    "The fine-tuned model can now:\n",
    "- Generate personalized running training schedules\n",
    "- Adapt to different user levels (beginner, intermediate, advanced)\n",
    "- Create weekly training plans for various goal distances\n",
    "- Output structured training data (days of week with activities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
